= Webサーバ

本章では、Android端末の世界から少し離れ、Webサーバを取り巻く世界を概観してみます。

Webサーバとは、要するに「Web」上の「サーバ」です。
この2つの言葉の意味を掘り下げていくことで、Webサーバをより深く理解出来るようになります。
@<fn>{expectation}

//footnote[expectation][本章はWebについてすでに利用経験があることを仮定しています。例えばWebブラウザやWebページについては、読者が扱ったことがある前提で話を進めています。Androidアプリ開発者でWebブラウザを使ったことがない、という方はいないだろう、という想定です。]

== クライアント・サーバ・モデル

サーバは英語でserverと書きます。
日本語でも、例えば「ジュースサーバ」「ビールサーバ」といった表現で登場します。
@<fn>{server}

//footnote[server][serverの本来の意味は「給仕人」「接客係」です。ちなみに給仕の読みは「きゅうじ」であって「きゅうし」ではありません。]

#@warn(TODO: 「ジュースサーバ」の画像が著作権フリーの画像ではない可能性)

//image[juiceserver][ジュースサーバー]{
//}

「ジュースサーバ」は人にジュースを提供します。
Webサーバは、簡潔に言えば「Webページを返すサーバ」です。@<fn>{wrong}

//footnote[wrong][このひとことでは十分でないから、本章があります。]

WebブラウザやAndroidアプリは、サーバから見て「クライアント」です。
クライアントとサーバのやりとりにおいては、

 * クライアントは、サーバにリソースを要求する。
 * サーバは、クライアントの要求を受け取り、要求に見合ったリソースを返す。

というやりとりが発生します。

特にWebでは、WebブラウザやAndroidアプリからWebサーバへ、Webページを「リクエスト」し、Webサーバが「レスポンス」を返します。
「レスポンス」にはしばしばWebサーバが持っているリソース（データ）が含まれます。
英単語が3つ出てきていますが、それぞれ以下のような意味です。

 * requestは「要求」
 * responseは「返答」
 * resourceは「資源」

WebサーバがAndroid端末に接続してくるということは通常ありません。
「リクエスト」は常にクライアント（Androidアプリ側）が行い、「レスポンス」をWebサーバが行います。

より一般的に、データを要求する側をクライアント、返答をする側をサーバと呼びます。
「クライアント・サーバモデル」という、インターネット・クラウドで非常に一般的なモデル（考え方）の一つです。

「AndroidとWebサーバ」の関係で言うと、サーバとクライアントの関係が逆転することはまずありません。
つまり、サーバはずっとサーバのままで、クライアントはクライアントのままです。

ただし、クライアントとサーバ一という役割一般について言えば、クライアントとサーバの役割が、コンピュータ同士で入れ替わることはあり得ます。

Webから一旦離れ、複数のAndroid端末間で、自宅に初めからあるWiFiネットワークを経由して対戦ゲームを行うケースを考えます。
多くのAndroid端末はクライアントですが、どれか一つはサーバになり、その他の端末からの接続を待つのが一般的です。
@<fn>{maxio_cart}

//footnote[maxio_cart][携帯ゲーム機のカートゲームなどを想像してみると少し分かりやすいかもしれません。なお冗談でもなんでもなく、コンピュータ一般の進歩の一部をゲーム産業が牽引してきた面があるのは、ゲーム嫌いでも覚えておいて欲しい知識です。ゲーム内の高度な表現を実現するためにコンピュータが発達し、その発達した領域が他のビジネスのような分野でも簡単に仕えるようになる、という現象はたびたび見ます。]

まず、サーバ側がゲームを行うための「部屋」を作り、その他の端末の接続を待ちます。
その他の端末はしばしば「ホスト」とも呼ばれるそのサーバへ、クライアントとして接続します。
プレイヤー全員が揃った段階で、ゲームを開始します。

上記のゲーム1プレイが終わった後、別の端末がサーバもしくは「ホスト」の役割は行うこともありえます。

例えば、上記のゲームでホストを担当していた人が自宅の用事で帰宅したとします。
ホストがいなくなったのでもうゲームが出来ないかというと、そうでもありません。
別の人がホストをすれば、同じゲームを一人少ない状態ながら、引き続き行うことが出来るかもしれません。
このとき、その別のゲーム端末が今度はサーバになります。


=== P2Pという別のモデル

クライアント・サーバモデルとは別のモデル（考え方）に、P2P（ピアツーピア, Peer to Peer）というものもあります。

インターネット上でファイルを共有する例を考えてみましょう。
クライアント・サーバモデルに従う場合、サーバがそのデータを
複数のクライアントに渡したり、逆にクライアントからデータを受け取り、
他のクライアントへ提供することになるでしょう。

この方法は、サーバへ負荷が集中するという問題があります。
全てのクライアントが特定の1台（もしくは少数）のサーバにアクセスするので、
どうしてもサーバ側が「重く」なりがちです。

一方、インターネット上では、1つの端末がサーバではない他の端末と直接通信することができます。
であれば、ファイル共有する際に、転送するデータを直接その2つの端末同士でやりとりさせれば済むはずです。
サーバがわざわざデータ置き場として仲介してあげる必要はありません。

このアプローチでは、サーバはその2者を「仲介」する情報だけを持っていれば済みます。
どの端末がどういったデータを持っていて、
インターネット上のどこにいるか、そういった情報だけを、
サーバとしてクライアントに提供すればよいでしょう。
そのあと、サーバから見たクライアントはお互いに通信をし始めます。

この考え方をもう一歩進めると、どの端末が何を持っているかの情報さえも、
サーバを介さず端末同士でやりとり出来ることに気づきます。
これを実現するためには、この端末（P2Pではしばしばピアともノードとも呼ばれます）同士が
自分たち全体をネットワークとして認識し、
そのネットワークで行う処理を分散して処理するように協調動作する必要があります。

クライアント・サーバモデルのように一台が中心になって機能するのではなく、
それぞれの端末（ノード）が、自分たちというネットワークの情報の一部だけを
保存しておき、情報を分け合うことで同様の目的を達せられるはずです。
このアプローチの良い点は、もはや中央集権的なサーバが要らなくなることです。

このようなノード間の自律的なネットワークを元にしたアプリケーションをP2Pと呼びます。

Peerは「同僚」といった意味の英語です。
ServerがClientにServe（仕える）という非対称の関係を明確に意図しているのに対して、
Peerは通信相手同士が同格であることが明確になっています。

P2Pモデルを採用するアプリケーションでは、
そのアプリケーションを理解する、インターネット上のノードが協調します。
そしてそれぞれのノードがバラバラに異なるノードと自律的に通信するのです。
クライアント・サーバモデルのように一箇所にリクエストが集中するわけではなく、
Webサーバのような中央集権的な仕組みなしに、データをやりとりします。

実際にはP2Pの中でも、サービス一部について管理サーバを立てていることはあります。
Skypeというインターネット電話は、インターネット上の通話については
P2Pのモデルを採用していますが、認証や課金に関する情報はサーバが管理します。
一方、サーバと呼べそうなものを一切置かないP2Pファイル共有ソフトも今では一般的です。

P2Pについての説明はここまでにしておくことにしましょう。


== プロトコルについて学ぶ
=== 相手がいるならルールが必要

相手がいなければ、自分でルールを決めてしまうことが出来ます。

自分のアプリケーション開発で、「このデータはHogeHogeClassが持つ」といった自分が決めたルールを途中で変えても、ユーザに見えない範囲では文句を言われることはあまりありません。
HogeHogeClassを継承したHogePostClassを新たに実装してしまっても気づく人はいないでしょう。
要は、新しいルールを決めたら、ただ自分がそれを守ればよいのです。
この場合、ルールなんて意識もしていないことのほうが多いのではないでしょうか。

しかし「クライアント・サーバモデル」や「P2P」のように相手がいる場合、
世界中に分散している他のコンピュータとやりとりをします。
相手がいる場合には何らかのルール、つまり「プロトコル」（protocol）が必要です。
@<fn>{network_should_have_done}

//footnote[network_should_have_done][「ネットワーク」の章でもTCP/IPといったプロトコルが出ているはずです。これも全く同じように、双方がルールを守って成立します]

インターネットに関する技術的な話を除くと、国家間の外交に関するニュース等で「プロトコル」という言葉を散見する印象を筆者は持ちます。
その場合は「外交儀礼」という意味で、例えば他国の王族をもてなす際には一定の手順、すなわちプロトコルを踏まえるのがならわしです。
この場合のプロトコル破ると、場合によっては外交問題になります。


=== スーパーに梅干しの在庫を問い合わせる

プロトコルの意味について考えるため、
仮想のスーパー「なるえつ」に「大山の梅干し」の在庫があるかを電話で確認する例を考えてみましょう。

日本のスーパーに対して梅干しを電話問い合わせする場合、
電話番号を入力して相手につながってからは大まかに以下のような流れになるでしょう。

 * （客）（電話をかけて繋げる）「もしもーし」
 * （店）「はい、スーパーなるえつです」
 * （客）「名前も名乗らぬ客です。大山の梅干しはありますか」
 * （店）「少々お待ちください（少し時間を置く）はい、在庫はあります。」
 * （客）「ありがとうございます」（電話を切る）

自然といえば自然な流れです。
ここでやりとりされている情報を分解すると、以下のようになります。
なおこの例では、スーパーなるえつの担当者はサーバで、問い合わせをする側はクライアントと見立てることができます。

会話の流れを順番に追ってみましょう。
まず、クライアントからサーバへ「接続」します。
ついでに「もしもーし」と相手へ挨拶してます。
@<fn>{no_request_on_the_protocol}

//footnote[no_request_on_the_protocol][電話問い合わせの場合、最初の「もしもし」が省略されるケースのほうが多いと思います。電話をかけてつながった時点で店は誰かから会話の要求があったことを理解出来るからでしょう。なお、何かのメッセージを省略できるかどうかもコンピュータの場合はプロトコル（ルール）で決めておく必要があります。]

サーバからの最初の返答で、クライアントは少なくとも相手が「スーパーなるえつ」と名乗っていることを理解します。

次に客は「自分は名乗るつもりはない」と延べ、「大山の梅干し」の在庫に関する情報を求めるリクエストを送っています。
ここでは「店は客が誰かを認識していないのに、在庫情報を店員が教えている」ことにとりあえず注目しましょう。
@<fn>{naruetsu_authorization}

//footnote[naruetsu_authorization][これが「金庫の中にいくらありますか」なら、きっと店員は知っていても客には教えません。]

「少々お待ちください」は特に人間同士で「そのレスポンスに対する回答には時間がかかる」ことを示すものです。
要求を処理する時間がかかった後、少なくともその要求に対してリソースがあることまでは、サーバ（スーパーなるえつの名前もしれぬ店員）は応答します。

残念ながら、電話口ではインターネットのようにクライアントは本物の梅干しを電話では直接受け取ることはできないので、
ここで電話のやりとりは終わりにして、実際に店舗に行った時に売り切れている恐怖と戦います。

=== プロトコルとは

コンピュータの分野でのプロトコルとは、異なる相手同士がやりとりをするルール・約束事のことです。
特に、インターネット上でクライアントとサーバが通信するには、何らかのプロトコルが必要になります。
プロトコルを文字におこした「仕様書」もあったほうが、後々のトラブルを防げます。
口約束で成立するプロトコルには限界があります。

オフィスで席を並べる同僚と一緒にサーバとクライアントを作る状況を考えます。
何もコミュニケーションなしに、二人の考えるデータフォーマットがピタリ一致することは普通ありません。
まず「俺はこういうデータを投げるプログラムを書くからな」という取り決めはきっとします。
「言った」「言わない」問題に発展しないよう、社内Wikiにルールを書いたら、それはすでに立派なプロトコル仕様書です。@<fn>{program_spec}

//footnote[program_spec][プログラムの仕様書なんて要らないという話を聞くかも知れません。本章全体を通じて、仕様書はプログラムのそれではなく、相互にやりとりする上で必要なプロトコルの仕様書で、性質が違います。]

アプリ開発と同様、サーバとクライアントの両方をただ一人が作っている場合、プロトコルは自由に変更出来ます。
しかし一般には、相手は別の会社のサーバだったりします。
ルールに基づいてアクセスしないと、無視されたり、あるいは悪者扱いされます。

スーパーなるえつの例では、人間同士でのある程度のプロトコル（しきたり）があるものの、
相手の応答がおかしければ、なんとかする余地がありました。
相手がすずらんの花のことを話し始めたら
「焦るな俺は大山の梅干しが食べたいだけなんだ。」
と返答すれば、もしかすると相手は正気に戻って会話が成立する余地があります。

しかしコンピュータは、人間以上にアドリブに大変弱いです。空気を読めません。
@<fn>{chainber}

//footnote[chainber][「彼はなんと言っている！？」とコンピュータに聞いたとき、コンピュータから丁寧に空気を読む回答をしてくるとすれば、そのコンピュータはチューリングテストにそのまま合格出来たと言えるでしょうか。ちなみにチューリングテストとは、ある機械が知的かどうか（人工知能であるかどうか）を判定するためのテストのことです（Wikipedia日本語版「チューリング・テスト」参照）]

コンピュータを用いたサーバとクライアントのやりとりでも、想定外の事態を含めていろいろな状況が起こりえます。
その状況を可能な限り網羅したプロトコル（つまりルール）を仕様書にまとめておき、
クライアントとサーバの双方が、そのプロトコルにしたがってデータを要求してデータを受け取る必要があります。

=== RFC（Request For Comments）

複数人が共有するプロトコルの場合、特定の誰かが一人でテキトウに決めるのでは問題があります。
その人が悪意を持っていたりすると他の人の迷惑になりますし、その人が気づかない問題があるかもしれません。
ビジネスの世界のように利害関係が絡むと、もっとややこしくなるでしょう。

インターネットやWebのように大量の異なるプレイヤーが絡む世界でこれは大変困るので、
みんなで議論してみんなでルール（プロトコル）を決め、みんなで守るようにします。
@<fn>{screw}

//footnote[screw][そもそも、業界の参加者間で仕様を共有するアイディア自体はありふれたものです。例えばネジの規格は種類があるとはいえ、ISOのような国際的な機関によって決められています。ネジを使うメーカーもネジを作るメーカーもそれに従ってものを作れば、とりあえずネジの役割を果たしてくれるはずです。]

インターネット、特に本章の中心であるWebでは、もともと情報をみんなで共有・公開する文化の元に成り立っています。
そのため、それを成り立たせるためのWebにまつわるプロトコル仕様は公開で議論され、その結果も自由に見ることが出来ることが望まれます。
そのための議論の場と仕様の公開場所を提供する「開かれた」組織が必要になるでしょう。

そこで本章で紹介しておきたいのがRFCです。

RFCは、IETF（Internet Engineering Task Force）によって発行・管理される、技術仕様等に関する文書を指します。
特にWebに関わる仕様の多くは、RFC（Request For Comments）と呼ばれる一連の文書により定義されています。
Webに限らずインターネット全体に関わる仕様がRFCによって規定されています。
@<fn>{w3c_and_rfc}

IETFは「開かれた」組織です。標準化のための作業部会（Working Group、ワーキンググループ）のメーリングリストに参加することで、誰でも標準化に関わる議論に参加することが出来ます。
実際、筆者も議論に参加したことがあります。（後述）

//footnote[w3c_and_rfc][Webに限らないインターネット全体に関する仕様をIETF、Webに関する仕様を前述したW3C（World Wide Web Consotium）が受け持つ、といった分担があるようです]

RFCと称されるドキュメントはたくさんあり、それぞれに連番がふられています。
「RFC」のあとに数字をつけ、例えば「RFC 7230」といった形で特定のRFCを参照します。

現時点でも7000を越えるRFC文書が存在しますが、全部がインターネット「標準」というわけではありません。
それぞれのRFCにはその文書のカテゴリ（Category）が記載されており、それによって各RFC文書の性質が分かります。
標準に関するものもあれば、例えばインターネットに関係する歴史に関するものもあります。
@<fn>{coffee}
RFCの歴史についてRFC 2555 "30 Years of RFCs"という文章まであります。

//footnote[coffee][エイプリルフールに発行されるRFCの中には完全にジョークのものがあります。1998年に公開されたRFC 2324の"Hyper Text Coffee Pot Control Protocol (HTCPCP/1.0)"などはわかりやすい一例です。私も以前その存在を知り、衝撃を受けた記憶があります。同RFCの"there is a strong, dark, rich requirement for a protocol designed @<b>{espressoly} for the brewing of coffee"（強調引用者）という表現から誰しもがコーヒーの芳醇な香りを想起しつつ、ええと、次へ]

Request For Commentsは日本語に訳すと「コメント求む」です。
実際には、各ドキュメントは「コメント求む」という表現から想像するよりも成熟した状態で公開されています。
各RFCの文書は公開される前に多くの議論を経た上で公開されており、以後、大きな修正は行われません。

「RFC XXXX」（Xは数字）と表現された場合、その表現が差す文書はいつも同じです。
誤りについてはerrataとして別の文書として公開されますが、根本的な改善については次のRFCを議論し、過去のRFCを打ち消す形で次に活かします。
@<fn>{json_rfc}

//footnote[json_rfc][RFC 7158は、2014年と示すべきところを2013年と記述してしまったという理由で一瞬でobsoleteになり、RFC 7159に取って代わられたとのことです。]

古いRFCの側は、文章の内容が訂正されることはありませんので、注意が必要です。
IETFが公開する、@<href>{http://tools.ietf.org/}から参照出来るRFCのHTML（例えば@<href>{http://tools.ietf.org/html/rfc7230}）からは、obsoleteとなったRFCについてはHTML上にその情報が記載されます。
一方、オリジナルのRFCとも言えるプレーンテキスト版（例えば@<href>{http://www.ietf.org/rfc/rfc2616.txt}）は本当に修正・変更がされません。


なお、RFCが標準仕様の全てであるかのような記述に見えるかもしれませんが、インターネットに関する仕様が全てRFCにまとまっているわけではありません。
RFCを紹介したのは、本章に関わるインターネットと特に「Web」の根幹に関わる仕様の多くがRFCとして公開されているためです。
インターネットの範囲に絞っても、他の標準化プロセスを持つISOやOASISなど、別の団体も多数あります。

共有されるインターネットの仕様書の中には、企業が独自に策定する、いわゆる「プロプライエタリ」なものもあります。
その場合、その企業の思惑に応じて仕様がねじ曲げられて、利用する他の人が迷惑を被ったりすることもあります。
RFCは言ってみればずっと「民主主義的」です。
@<fn>{proprietary_is_bad}

//footnote[proprietary_is_bad][Web上で「プロプライエタリ」という表現が使われると、悪いニュアンスとセットであることが多いです。共有や公開を一つの理念としているべきインターネット、という考え方とそぐわないからと筆者は理解しています。]

これから登場するWebに関わる多くのプロトコルには、RFCに基づいたプロトコルが存在します。

=== デファクトスタンダード

デファクト（デ・ファクト、de facto）は「事実上の」という意味を示すラテン語で、名分規定はないものの慣習上使われているルールなどに対して使われる表現です。
対応する明文化された（ある意味で「しっかりした）標準は「デジュールスタンダード」（デジュールは"de jure"）と呼ばれます。

プロトコルやRFCについて明文化された仕様が大事であると説明しましたが、世の中にはしばしば例外が存在し、例外があたりまえのように使われることがあります。

WebにおいてはRFCに書かれた内容に「バグ」があった場合、仕様であるが無視される、あるいは明確に否定されるということが起こることがあります。
仕様を書いた時点では良かれと思ったことが、実際に実装しきってみるととんでもない間違いだった場合、「デジュール」にだけ頼ると世の中が崩壊します。
そこで、最先端ではしばしば「俺らはこのルールは無視する」といったことが正しい目的で行われたりします。

一方その逆に、企業が商業的な理由などで標準外の挙動を示すプロダクトを提供したりすることもままあります。
このように書くとすべてがすべて悪かのようですが、Ajaxを始めとする次世代Webの皮切りとなったのは、
Microsoftが標準も何もない新しい挙動を示すXMLHttpRequestという機能をWebブラウザにとってつけたのが始まりです。
@<fn>{ajax_purpose}

//footnote[ajax_purpose][同社のPCソフトウェアのオンライン版機能を強化する目的だったとのことです。]

技術の進歩は仕様によって始まるわけではありません。
Web上でも実験は必要ですし、その場合、仕様と実装の世界的な共有はおそらく伴いません。
仕様があるがそこに明らかな問題（バグ）が後から発見されることもあります。
あるいはバグとは言いがたいものの、仕様の曖昧さを回避するため皆が暗黙のノウハウを貯めることもあります。
RFCのように明確に書かれた仕様の中にも、意図通りに世の中で適用されている事例と、そうでない事例が混在することはしばしばあります。

Webで使われるルール（プロトコル）一般にそういった事例が散見されるため、必ずしも全てがきっちり書かれた通りではない、ということも併せて覚えておいてください。

== Web以外の「サーバ」

本章を始めとする一連の説明は、Webサーバについての説明を中心としています。
しかしインターネット・クラウド上にあるサーバはそれだけにとどまりません。
Webについて本格的に学ぶ前に、その他のサーバについて解説しておきます。

例えば、家庭やオフィスでも以下のようなサーバが設置されていたりします。

 * ファイルサーバ
 * プリントサーバ
 * メールサーバ

「プリントサーバ」について補足しましょう。

Word文書などを印刷したりするために、プリンタを利用することがあります。
昔のプリンタは、USB接続やその他の接続方法でPC1台としか接続・通信できませんでした。

しかし業務用プリンタや最近のプリンタは賢くなっています。
複数台のパソコンやAndroid端末などから「このデータを印刷して」という要求を受けて、印刷を行います。
リクエストを受けて、レスポンスとして印刷するので、これもサーバです。

Webサーバと通信するためにプロトコルとしては後述するHTTPが重要です。
同様に、各サーバではその用途に応じてプロトコルが必要です。

 * メールサーバ ... POP, IMAP, SMTPなど
 * プリントサーバ ... IPP, LPRなど
 * ファイルサーバ ... SMBなど

これらのプロトコルの多くも、RFCのような仕様によって通信方法が定められていたりします。


== Web

ここまでで「サーバ」と、クライアント・サーバ間のようなコンピュータ同士が通信する上で重要な「プロトコル」についての説明が終わりました。
「Webサーバ」とは要は「Web」におけるサーバで、その分野のためのプロトコルがあります。

では「Web」とは何でしょうか。

Webという英単語は、もともと「蜘蛛の巣」を意味する英単語です。
この用語に絡めて、1990年にスイスのCERNという研究所に所属していたTim Berners-Lee博士がWorld Wide Webを提唱したのが、
現在のインターネット上のWebという言葉の始まりです。World Wide WebはWWWと略されることもあります。
今では単にWebと呼ばれることも多いため、本稿では以降「Web」で一貫することにします。
@<fn>{internet_existed_before_www}

//footnote[internet_existed_before_www][情報共有を行う手段自体は1990年以前から存在しました。例えばWikipediaの「電子メール」の記事によれば1965年に世界最初の電子メールが使われ始めた、とあります。]

もともと技術論文は、研究分野の他の論文を引用・参照しつつ研究を発展させます。
Web以前からあるコンピュータ上のドキュメントでも、ひとつのドキュメントと
他のドキュメントを相互参照する仕組みは備えていました。

同様に、インターネット上の文章にも同様の構造を作ることが出来るのではないか、
という着眼点から、世界全体を一つの蜘蛛の巣と見立てるWorld Wide Webの発想を、
提案書の形でインターネット上に公開したのがTim博士です@<fn>{www_proposal}。
一つ一つのハイパーリンクという他のドキュメントへの参照が蜘蛛の糸となります。

この後、1993年にイリノイ大学NCSA（Natiotal Center for Supercomputing Application）
がWebブラウザ"Mosaic"を公開し、大ヒットとなります。
以後、Webの利用は爆発的に普及し、今に至ります。
@<fn>{more_info}

//footnote[www_proposal][最初の提案をW3C（The World Wide Web Consotium）のWebサイト@<href>{http://www.w3.org/Proposal.html}で読むことが出来ます。ブログやTwitterどころかWebページという概念が一般に存在しない時代のことですので、大変先進的と言えます。]

//footnote[more_info][なお本章の説明も含め、WWWの説明はしばしば、まるでTim博士が一人でWorld Wide Webを発明したかのようなニュアンスになりがちなのですが、実際にはいろいろな主体が影響を与え合う中で登場・進化したと考えるのが適切でしょう。例えばWebの成功のきっかけとして紹介されるWebブラウザMosaicはTim博士の発明ではありません。本章執筆担当者が眺めた日本語書籍の中では『Webを支える技術』がおそらく細かな時代背景をよく説明していると思いました。もっと細かくWebの歴史を知りたければそういった書籍をあたってみるほうがよいでしょう。]

Webでは当初から、相互にリンクのある「ハイパーテキスト」をWebサーバに配置し、それを人がWebブラウザで見るという用途が想定されています。
これを達成するため、まず3つの主要が重要であると言われます。

 * HTML（Hyper Text Markup Language）は、「ハイパーテキスト」を記述するためのマークアップ言語@<fn>{markup_language}です。
 * URI（Univarsal Resource Indicator）は、世の中のモノ（リソース）を一意に指し示すための文字列の仕様です。
 * HTTP（Hyper Text Transfer Protocol）はHTMLをWebブラウザが要求してWebサーバが返答するやりとり自体に用いるプロトコルです。

//footnote[markup_language][マークアップ言語は「文章の構造（段落など）や見栄え（フォントサイズなど）に関する指定を文章とともにテキストファイルに記述するための言語」です。（Wikipedia日本語記事より）有名なものとしてHTMLがあります！]

=== HTML

本章を読んでいる人はさすがにWebページを全く見たことがないという人はいないでしょうし、
HTMLがWebページを記述するマークアップ言語だということも誰もが知っていることと思います。

そこでここではHTMLの説明を一旦省略します。

#@warn(TODO: HTMLの説明も書く)

=== URI（Uniform Resource Indicator）

WebページでリンクをクリックしたときにWebブラウザがインターネットにつながっているのに「それ、どこかわからない」というのでは困ります。
Webで情報をやりとりする際、Web上のどのサーバのどこにリソースがあるかを指定できるのが便利です。
この方法としてURIが規定されています。
@<fn>{uri_rfc}

//footnote[uri_rfc][RFC 3986 "Uniform Resource Identifier (URI): Generic Syntax" に詳細な説明があります。]

例えば架空のお天気情報Webサイトが@<href>{http://weahter.example.com/earth/japan/tokyo/taito-ku/2015/01/10}というURIを提供していたとしますと、これはHTTPというプロトコルで動作する、weather.example.com上の"/earth/japan/tokyo/taito-ku/2015/01/10"というpathにあるリソースを意味します。
架空の例なのでなんとも言えませんが「台東区の2014年7月11日の天気」というリソースを提供していそうです。

技術サークル「Tech Booster」の、Webサイトの、トップページを示す一意の表現を得ることが出来ます。

@<list>{uri_format}に同RFCに記載されたURIの例と対応する部品の名前を示しましょう

//list[uri_format][URIのフォーマット]{
     foo://example.com:8042/over/there?name=ferret#nose
     \_/   \______________/\_________/ \_________/ \__/
      |           |            |            |        |
   scheme     authority       path        query   fragment
      |   _____________________|__
     / \ /                        \
     urn:example:animal:ferret:nose
//}

特に@<list>{uri_format}の上部のURI（fooというスキームで始まる方）はWebでよく良く見るものかと思います。
Webブラウザで@<href>{http://weahter.example.com/earth/japan/tokyo/taito-ku/2015/01/10}のようなURIをクリックすると、そのWebページを表示しようとします。
HTMLで言えば<a href="...">というタグで記述するさいに使われることが多いでしょう。
@<fn>{about_example_com}

//footnote[about_example_com][Webに関する記述ではよくexample.comというドメインを見ることがあります。このホスト名、例示用のホスト名としてRFCに規定があります（RFC 6061 "Special-Use Domain Names"）。example.jpなども同様です。]

URIには上記のように全ての情報を記述する「絶対URI」と、"../../06/10"のような「相対URI」があります。
クライアントがどこかのURI上のリソースを見ていることが明らかな場合、
httpから記述するのではなく、現在位置からの相対位置を記述するほうが便利なことがあります。
「相対URI」はそういったときに使われます。
相対URIの省略された部分はWebサーバがルールに基づいて補完します。

本章ではURIの詳細を説明することはしません。
RFCを読めば良いからですし、他著のほうが優れた説明をしているであろうからです。

その代わりに、普段目を向けないところに焦点をあてて、
今後の開発の「勘」などを磨けるようなトピックをいくらか埋め込むことにします。
@<fn>{uri_is_too_popular}

//footnote[uri_is_too_popular][普段使っているものほど「知っているので大丈夫」と思いがちです。Webの界隈は特にそういうことが多いような気がするなぁ、という本章筆者の考えからこんな感じになってます。]

==== URI, URL, URNの違い

URIについて覚えておいて欲しい最初のポイントは「URIは世の中の一つのリソースを指し示すもの」という点です。
なので、正確に言えばWeb上のハイパーリンクだけがURIが果たせる唯一の役割ではありません。

読者の方の多くは、URL（Universal Resource Locator）という表現の方を多く見ているかもしれません。
実際これは現在でも普通に使われている表現です。
一方現在では、WebサーバーやHTTPの仕様上で使われる表現はURIです。
@<fn>{url_is_used}

//footnote[url_is_used][実際、本章を執筆する上で参考にした書籍の一部は、本章の議論を理解した上でも、URIではなくURLという表現を好んで使っている節がありました。]

歴史的にはURLという概念が先に登場しました。
前述した当初のWorld Wide Webでも、他のWebページへのハイパーリンクを作成する際に、相手のWeb上の「場所」を特定できる必要があったためです。
1994年に、WWWの提唱者であるTim博士が共著者としてRFC 1738 "Uniform Resource Locators (URL)"が発行されています。

しかしその後、リソースを特定する上では「場所」だけでなくその「名前」自体も同様のフォーマットで一意に特定できるべきだ、という議論が主流となります。
最終的に「場所」を示すURLという概念に加えて「名前」を示すURN（Universal Resource Name）も一般的に認知されるようになりました。
@<fn>{other_ur}

//footnote[other_ur][なお他にも"Uniforme Resource"で始める別の概念とフォーマットが提案されたそうですが、現在では一般的ではないそうです。]

URLとURNは人間で言う氏名と住所の違いに近いと言われます。
例えば商業書籍を考えてみます。
本を一意に認識する上でISBN番号というものがありますが、ISBN番号を表現するURNとして"urn:isbn:4844335340"という文字列を用いることができます。
このURNによって、『Effective Android』という技術書を一意に指し示すことができます。

ただし、URNではEffective Androidという技術書を一意に特定できても、
Web上のどこにその本の情報があるか、どこで購入できるか、といった場所についての情報は伴いません。
その目的のため、Web上の場所を指す場合に「場所」を一意に特定するURLを使用します。
"urn:isbn:4844335340"をオンライン書店Amazonで購入する場合、
@<href>{http://www.amazon.co.jp/dp/4844335340}へアクセスしてください、といった説明ができます。

URLとURNをまとめてURIと呼びます。

URNは「場所」を示すことが出来る「URL」としての役割を果たすことはありません。
HTMLのhrefとして記述してもWebブラウザは多分どこにも移動してくれません。
URIということで<a href="urn:ietf:rfc:1458">RFC 1458</a>と書いてもこのリンクはWebブラウザ上では意味がないでしょう。

URIで「インターネット上のリソースを識別する」と表現するもの、とするのもまた、実は正確ではありません。
特にAndroidアプリで@<href>{tel:+1-201-555-0123}というURIを見たら、これはインターネット上のリソースではなくアメリカ国内の特定の電話番号を指し示すはずです。
@<fn>{rfc3966}

読者が想像する"URL"のイメージに一番近いのは、httpもしくはhttpsというscheme要素を持つURIのこと、ということになるでしょう。

//footnote[rfc3966][RFC 3966 "The tel URI for Telephone Numbers" の例ですが、特に例示用の番号であるといった情報は見つかりませんでした。もし電話がかかったら"Sorry"と言って、切りましょう。]

RFC 3986の記述を参照する限り、今後のWebに関する議論では、URLに相当する情報を強調する特別な目的がない限りは全てURIで統一するのが適切です。
一方、今でもURLという表現がWebサーバやその周辺実装の説明では自然に登場します。
今後もこういう状況は起こり続けるでしょうが、本章読者は一応準備だけはしておきましょう。

====[column] まだURNのことがわからない場合のもう一例

本章筆者はURNの意味が長いこと理解できませんでした。
そういった方がいらっしゃる可能性を想定し、あえてコラムでもう一度、URNについて取り上げることにします。

RFCという言葉について考えてみましょう。
ここまでの説明を読むと「RFC1458」という文字列からはRequest For Commentsの1458番という技術文書のことだと予想したくなります。

しかし実は@<b>{ラジオ福島}のことかもしれません。
周波数として1458kHzを使っていて、かつ短縮名が「RFC」なのですね。
@<fn>{radio_fukushima}

//footnote[radio_fukushima][@<href>{http://www.ustream.tv/user/rfc1458}というURIは存在し、どうやらこれはラジオ福島のユーザアカウント情報を表示するWebページのURIです。]

要は「RFC1458」という表現では、世の中の人が同じものを想像をして議論するには不十分です。
一方がその番号の技術文書の内容がダメだという意味で「RFC1458マジダメくさい」とTwitterで書くと、
ラジオ福島の人がそれを見てしょんぼりしてしまうのです(´・ω・｀)

一方urn:ietf:rfc:1458であればRequest For Commentsの1458番であると間違いなく判定できます。

====[/column]

==== URI内の「デファクトスタンダード」

URIという表現で私達が想像しているものと仕様の中身がずれていることがあります。

前述したURIの要素の中には、後述するHTTPのGETリクエストで特によく使われるquery要素の記述もありました。
ちょっともう一度眺めてみましょう。

//emlist[URIのフォーマット（再掲）]{
     foo://example.com:8042/over/there?name=ferret#nose
     \_/   \______________/\_________/ \_________/ \__/
      |           |            |            |        |
   scheme     authority       path        query   fragment
      |   _____________________|__
     / \ /                        \
     urn:example:animal:ferret:nose
//}

query要素でよく登場するのは、key=valueというプログラミング言語で言うMap・辞書型の構造です。
さらに&で文字列を区切って、複数の辞書型データを記述する記法も当たり前のように使われています。

あまりに当たり前に使われているので、この挙動が仕様の一部かと言われると、実はそうではないようです。
URIの仕様と言えるRFC 3986該当部分を（ページ境界を取り除いて）掲載してみます。

//emlist[RFC 3986のQuery]{
3.4.  Query

   The query component contains non-hierarchical data that, along with
   data in the path component (Section 3.3), serves to identify a
   resource within the scope of the URI's scheme and naming authority
   (if any).  The query component is indicated by the first question
   mark ("?") character and terminated by a number sign ("#") character
   or by the end of the URI.

   query       = *( pchar / "/" / "?" )

   The characters slash ("/") and question mark ("?") may represent data
   within the query component.  Beware that some older, erroneous
   implementations may not handle such data correctly when it is used as
   the base URI for relative references (Section 5.1), apparently
   because they fail to distinguish query data from path data when
   looking for hierarchical separators.  However, as query components
   are often used to carry identifying information in the form of
   "key=value" pairs and one frequently used value is a reference to
   another URI, it is sometimes better for usability to avoid percent-
   encoding those characters.

   (以下、参考訳)

   query要素は階層構造になっていないデータを保持する。
   同要素はpath要素を伴って存在し、URIのsheme要素、
   (もし存在すれば)authority要素のスコープ内にあるリソースを識別するのに
   用いられる。query要素は冒頭のクエスチョンマーク("?")によって
   その存在があることが明示され、シャープ記号("#")かURI末尾によって
   終端が明示される。

   query       = *( pchar / "/" / "?" )   (訳注: RFCで良くあるEBNF記法)

   スラッシュ("/")やクエスチョンマーク("?")がquery要素に含まれていてよい。
   ただし関節参照むけのベースURIとしてそれらが使われた際、
   古いぼっこわれた実装はまともにそういったデータに対応できないことがある。
   （訳注: ベースURIは同RFC内の他の章の知識が必要。説明は省略）
   階層構造を示すセパレータ(訳注: path要素の"/"のこと)を探している際に
   queryに該当するデータとpathに該当するデータを分割するのに失敗しがち
   だからである。しかし（訳注: そういった文字列をパーセントエンコーディング
   させたくなる気持ちはわかるが)、query要素はしばしば"key=value"の
   複数の組み合わせで取り扱われ、しかもそこでよく使われる値の種類として
   別のURIへの参照があるることを考えると、それらの文字("/"と"?")を
   パーセントエンコーディングしないほうがよいこともある。
//}

ポイントは後半のパーセントエンコーディング周りの説明です。
実際に今述べた"key=value"の「複数の組み合わせ」("pairs")がしばしば使われる、
とは書いてありますが、
具体的にそのデータを使わなければならない(MUST)とはひっとことも書いてありません。
@<fn>{tangled_web_says_same}

//footnote[tangled_web_says_same][『めんどうくさいWebセキュリティ』でも、"&"で区切る方法は仕様にはなくデファクトスタンダードという説明があるので、この解釈で間違いないようです。]

なので、相当困った際にはここに許されている限りの文字を詰め込んで特殊なことをやっても「仕様違反じゃないもん！」って叫ぶことが一応出来ます。
@<fn>{no_support_maybe}

//footnote[no_support_maybe][ただし後述するWebアプリケーションフレームワーク等はその構造をしばしば自動的にうまく辞書データに変換してくれたりします。独自路線の場合、生データのURIから自分で解析処理する必要が発生します。余程の理由がなければ独自路線は避けたほうがよさそうです。]

その次の#の後に並ぶfragmentも状況は似ています。

//emlist[FragmentのRFC上の説明の一部]{
3.5.  Fragment

   The fragment identifier component of a URI allows indirect
   identification of a secondary resource by reference to a primary
   resource and additional identifying information.  The identified
   secondary resource may be some portion or subset of the primary
   resource, some view on representations of the primary resource, or
   some other resource defined or described by those representations.  A
   fragment identifier component is indicated by the presence of a
   number sign ("#") character and terminated by the end of the URI.

   (以下省略。実はqueryよりだいぶ長い)
//}

"secondary resource"とはありますが、それが具体的に"primary resource"から見て
どういうものであるかの解釈には幅がある表現となっています。

Webでは良く、HTMLで記述されたWebページの特定のヘッダに移動するために
fragment部分が活用されていますが、これが唯一絶対の使い方というわけではないわけです。

#@warn(TODO: 余裕があればあとで書く)
#@# ====[column]  JavaのURLクラスとURIクラス

#@# JavaにはURLとURI、両方のクラスがあります。
#@# ここで本章担当者としては紹介せずにいられないJava Puzzleがあります。
#@# http://youtu.be/wDN_EYUvUq0?t=9m50s

#@# 相当古い動画なのですが、仕様上今でも問題になるURLクラスとURIクラスのSet内挙動が異なる点を
#@# 指摘した例として、当時新入社員だった筆者としても大変驚いた記憶があります。

#@# 調べたところ、URLクラスはJDK1.0、URIクラスは1.4の導入とのことです。

#@# どちらかというと初期のJavaのライブラリ設計の失敗に関わるものですが、
#@# 「古い」というのはしばしばそういう問題も引き起こす、ということで一つ。

#@# ====[/column]

=== HTTP

ネットワークの章でTCP/IPの上で複数の異なるプロトコルのパケットが行き来していることを学んだかと思います。
Webサーバの場合にTCP/IPの上で使われるのは、HTTP（Hypertext Transfer Protocol）というプロトコルです。

Webサーバとやりとりする基本的なプロトコルであるHTTPでは、
クライアントからサーバへ要求（リクエスト、request）を送り、
サーバがそれに対する応答（レスポンス、response）を返します。
WebサーバはTCP/IPの80番ポートを用いるのが通常ですが、必須ではありません。

HTTPはWebの屋台骨となるもので、理解するのは結構大変です。
まず実際にHTTPで通信される中身を見てからプロトコルの中身を勉強することにします。

==== telnetでHTTPのリクエストとレスポンスを見てみよう

HTTPの詳細に踏み込む前に、実際にHTTPのリクエストとレスポンスを体験してみることにします。
ここで最初に登場するのは、telnetというコマンドラインツールです。
@<fn>{telnet_has_rfc}

//footnote[telnet_has_rfc][Telnetはサービスの名前で、RFC 854に仕様がありますが、現在でそのサービス自体がTelnetサーバとセットで使われることはまれです。このツールはそのサーバと通信するためのプログラムなため、実際にはHTTPを通信するものではない点は理解しておきましょう。詳細をコラムで述懐します。]

telnetはいわゆる「ターミナル」上で動作するプログラムで、標準でインストールされているOSもあります。
@<fn>{about_telnet_installation}

//footnote[about_telnet_installation][筆者の使用しているOS X 10.9.4、Debian/Ubuntu系Linuxでは標準でインストールされているようです。CentOS 6ではパッケージ管理ソフトyumからtelnetパッケージを指定することでインストールできます。Windowsの最近のバージョンではtelnetプログラム自体はインストールされているのですが、標準では無効になっているそうです。Web検索をすると使用する方法の記載があるので、それぞれのバージョンにあった方法で有効化してから、本章の例を試すことは可能です。]

@<list>{telnet_example}にTech InstituteのWebページヘアクセスした例を示します。
@<fn>{other_web_page}

//footnote[other_web_page][別のWebサイトでも試せますが、まずWebブラウザでそのWebページを表示できること、さらにそのURIがhttpsではなくhttpであること（URIの冒頭のhttpのあとに「s」がついてないこと）を確認してからのほうがよいでしょう。ここでの詳細な説明は省略しますが、httpsはHTTPにさらに暗号化を施すプロトコルで、今回のように人間がタイプしてhttpsを用いたWebサーバと通信するには、別の準備が必要になります。]

//list[telnet_example][telnetコマンドの実行例]{
$ telnet techinstitute.jp 80[Enter]   <--- "telnet" 以降を入力してエンターを押してください。
Trying XXX.XXX.XXX.XXX...    <--- 実際には正規化されたIPアドレスが表示されます
Connected to techinstitute.jp.
Escape character is '^]'.
GET / HTTP/1.1[Enter]   <--- "GET / HTTP/1.1"と入力してエンターを押してください
Host: techinstitute.jp[Enter]   <--- 上と同様エンターを押します
Session: close[Enter]  <--- 上と同様
[Enter]           <--- 最後に何も入力せずに再度エンターを押します
HTTP/1.1 200 OK
Date: Sun, 06 Jul 2014 06:19:43 GMT
Server: Apache/2.2.23 (Unix) mod_ssl/2.2.23 OpenSSL/1.0.1h
X-Powered-By: PHP/5.5.9
Connection: close
Transfer-Encoding: chunked
Content-Type: text/html

13e
<!doctype html>
<html>
<head>
<meta charset="UTF-8">

..(HTMLぷしゃー)

</html>

0

Connection closed by foreign host.
$   <--- telnetコマンドが終了します
//}

空行でエンターを押した後は、Webサーバが実際にHTTPのレスポンスをtelnetのアプリケーションに返答します。
@<fn>{maybe_bad}

//footnote[maybe_bad][本当は許可を得て使うところです。後述するウェブ・スクレイピング同様、あまりやらかすと本当に怒られるので、本稿を書いている担当者は実はちょっとビビりながら書いています。]

実際に入力した内容を追いかけながら、HTTPのリクエストとレスポンスについて順番に状況を追ってみましょう。

//list[telnet_example_part1][telnetコマンドの実行例（１）]{
$ telnet techinstitute.jp 80[Enter]   <--- "telnet" 以降を入力してエンターを押してください。
Trying XXX.XXX.XXX.XXX...    <--- 実際には正規化されたIPアドレスが表示されます
Connected to techinstitute.jp.
Escape character is '^]'.
//}

@<list>{telnet_example_part1}ではターミナルからtelnetコマンドを実行し、techinstitute.jpの80番ポート（HTTP）へアクセスを指定しています。
これによって、telnetがWebサーバへTCP/IP接続を開始します。

それ以降の3行はtelnetコマンドがコマンドを実行したユーザへわかりやすく文字列を表示しているもので、HTTPとは関係がありません。@<fn>{about_telnet_messages}

//footnote[about_telnet_messages][背後でTCP/IPを介してXXX.XXX.XXX.XXXというIPアドレスのサーバ（の80番ポート）へ接続し、接続が成功したことを伝えています。最後の"Escape character is '^['"は接続をクライアント側から終了する際に、ユーザがCtrl+\]を入力すればよいことをtelnetコマンド自身が伝えています。]

//list[telnet_example_part2][telnetコマンドの実行例（2）]{
GET / HTTP/1.1[Enter]   <--- "GET / HTTP/1.1"と入力してエンターを押してください
Host: techinstitute.jp[Enter]   <--- 上と同様エンターを押します
Connection: close[Enter]  <--- 上と同様
[Enter]           <--- 最後に何も入力せずに再度エンターを押します
//}

@<list>{telnet_example_part2}ではユーザは実際にHTTPのリクエスト、具体的には「GETリクエスト」を送っています。
説明を端折ったものを@<list>{telnet_example_part3}に示しましょう。

//list[telnet_example_part3][telnetコマンドの実行例（3）]{
GET / HTTP/1.1
Host: techinstitute.jp
Connection: close
       (ここの改行でリクエストヘッダの終了を明示している)
//}

最初の行はリクエスト行（Request Line）と呼ばれています。
その次の行から空行までの「〜: 〜〜」で記述された2行は「ヘッダフィールド（Header Fields）」と呼ばれます。

改行コードについて、現在コンピュータ上ではCR、LF、CRLFの3種類がしばしば混在して使われていますが、HTTP 1.1では改行は「CRLF」と決まっています。
@<fn>{telnet_may_not_use_crlf}

//footnote[telnet_may_not_use_crlf][なお、telnetコマンドは元々のTelnetサービスの都合上、デフォルトでCRを送ることがあります。本章筆者がLinux環境で他のコマンド（tcpdump）で確認したところCRLFが送られていましたが、他の実装での動作は定かではありません。]

3行からなるGETリクエストの冒頭で、実際に取得したいコンテンツとHTTPのバージョンを指定しています。
実は半角空白で区切られた真ん中の"/"がコンテンツの場所を意味しています。
今回の場合この最初の行は"GET http://techinstitute.jp/ HTTP/1.1"と同じ意味です。
ヘッダに含まれている"Host"行と"Connection"行については一旦おいておきます。

//list[telnet_example_part4][telnetコマンドの実行例（4）]{
HTTP/1.1 200 OK
Date: Sun, 06 Jul 2014 06:19:43 GMT
Server: Apache/2.2.23 (Unix) mod_ssl/2.2.23 OpenSSL/1.0.1h
X-Powered-By: PHP/5.5.9
Connection: close
Transfer-Encoding: chunked
Content-Type: text/html

13e
<!doctype html>
<html>

... （HTML）

</html>

0

Connection closed by foreign host.
//}

この部分は全てWebサーバから送られてくる「レスポンス」です。
一行目（"HTTP/1.1 200 OK"）はステータス行（Status Line）と呼ばれ、
実際にWebサーバが返答するHTTPのバージョンと、リクエストがどう処理されたかの「ステータスコード」
が記述されます。
それ以降、空行まではやはり「ヘッダ」です。
ここにサーバの情報や返答してきたデータの種類などが記述されています。
具体的には「Apacheと呼ばれるアプリケーションでホストされていること」
（"Server: Apache/2.2.23 ..."）や
「プログラミングPHPを用いて実装されたサービスであること」
（"X-Powered-By: PHP/5.5.9"）、
「返答したデータがHTMLであること」（"Content-Type: text/html"）
などが記載されています。

そのあと、空行（CRLF）を挟んで、実際のデータです。メッセージボディと呼ばれます。

なお今回の例では、Webサーバへ送ったリクエストの方には、改行の後のメッセージボディを何も入力していません。
これは単にメッセージボディが今回のリクエストでは空であっただけで、場合に寄っては送ることもあります。
例えばWebページでよくある問い合わせフォーム等では実際にボディにデータが入ることがあります。
なので、「最初の1行」「ヘッダ」と「ボディ」という構造は、HTTPのリクエストとレスポンスの両方で共通しています。
@<fn>{chunked}

//footnote[chunked][レスポンスのメッセージボディですが、HTMLの前にこっそり"13e"とあり、さらに末尾に0という数字もついています。つまりHTMLを返すよ、と言っていながらも、Webサーバが実際に返すメッセージボディにはHTML以外の「ゴミ」が混じっています。これはレスポンスヘッダにある"Transfer-Encoding: chunked"の指定があるためです。一般的なHTTP関連の教科書や入門的な説明では、直接HTMLデータだけメッセージボディに入るのですが、今回試したWebサイトがこういうリアルな返答をしばしば返したので、ややこしいですがあえてそのまま表記します。HTTPレスポンスについての説明のところでもう少し説明します。]

telnetでHTTPを実際に「しゃべって」みました。
ここからHTTPのリクエストとレスポンスの基本的な構造についてもう少し説明していきます。

#@warn(TODO: Windows8でのtelnetの使い方を書く)
#@# ====[column] Windows8でのtelnetの使い方
#@# ====[/column]

====[column] telnetを使うべきなの？

本コラムは初心者向けではありません。
筆者の頑張り物語の始まりだよ。

一般的にはHTTPのパケットの中身をみるのにtelnetを使う例が氾濫していること、
また各OSで比較的足並みを揃えやすそうと考え、本章でtelnetを使う例を挙げました。

ただ、果たしてこの方法が「正しいのか」は、単純に気になりました。
生のTCP/IPのやりとりを観測する方法として、
果たしてTelnetサービスのためのコマンド"telnet"が適切であるかを考えたかったわけです。

直観的には「ノー」です。
実際、本稿執筆時、「telnetコマンドはCRを標準で送る」ということを記述していました。
これはHTTPの観点からはプロトコル違反なので、そういう説明をしようとしました。

ただ、間違っていると困るので、tcpdumpでパケットを見たところ、
Linux系OSではCRLFをきちんと送っていて「おや」となったのです。
むしろ、"toggle crlf"を無視してまでCRLFが矯正されているような挙動でして、
首を掻き毟りたくなりました。

あるWeb上の記事にはtelnetコマンドを使うのは微妙、という説明もあります。
Telnetの元のサービスの仕様では接続時に読み取れないバイトを冒頭の接続時にやりとりするためです
（@<href>{http://superuser.com/questions/497962/}）。

また、Wikipedia英語版のTelnetの記事にも現在、Telnetプロトコルを前提とした
コマンドラインツールで生のTCP/IPをエミュレートするのは一部の
バイトデータの解釈ミスを引き起こすため厳密には正しくない旨、
説明が書かれています（@<href>{http://en.wikipedia.org/wiki/Telnet}）

しかし一方、Linux系OSのマニュアルには面白い記述があります。

//emlist[Linux系OSのtelnetのマニュアルより]{
When connecting to ports other than the telnet port, telnet does not attempt telnet
protocol negotiations. This makes it possible to connect to services that do not sup‐
port the telnet protocol without making a mess.
//}

一方CRLFの取り扱いについての説明はありません。
俺は何を信じればいいんだ。

なお、そもそもtelnetコマンドという言葉で全てをごまかすのが良くないんだ、という意見は正しいと思います。
Windows系のtelnetコマンドはこのような親切（？）設計にはあまりなっていないようで、
検証時にも混乱がありました。
でも、ある意味ではそちらのほうが良かったのかもしれません。

本章ではtelnetでTCP/IPを叩く方法は「使っても、まぁ、いいよね」という立ち位置で書いています。

====[/column]

==== HTTPのリクエスト

telnetの例でのリクエストをもう一度見て未ましょう。

//list[telnet_example_part3_2][telnetコマンドの実行例（3）再掲]{
GET / HTTP/1.1
Host: techinstitute.jp
Connection: close
       (ここの改行でリクエストヘッダの終了を明示している)
//}

TCP/IPでWebサーバへの接続が完了後、
クライアント（Webブラウザ等）は最初の行（リクエスト行、Request Line）で、
リクエストの種類（リクエストメソッド、Request Method）、
リクエストの対象、そして自分が利用しているHTTPのバージョンの3つの情報を指定しています。

リクエストメソッドについて、HTTPにはたくさんの種類がありますが、
ここで学ぶのは「GET」リクエストと「POST」リクエストです。
両方共クライアント、つまりWebクライアントの側から送るリクエストの種類です。
@<fn>{other_http_methods}

//footnote[other_http_methods][リクエストはPUT・HEAD・DELETE・OPTIONSなど今回説明を省略するメソッドも含めて合計で8つあります。]

ここではGETメソッドの対象として"/"、つまりルートディレクトリのデータを要求しています。
HTTPのバージョンは1.1を期待しています。
大方のWebサーバは要求通りHTTP/1.1でレスポンスを返してくれますが、必須ではありません。

2行目から空行まではヘッダで、必要なフィールドとして"Host"が定義されています。
HTTP/1.1ではこのヘッダ情報は必須です。

"Connection"行は必須ではありませんが、今回はサーバ側の応答の関連でつけています。
今回の例でこれを付けずにGETリクエストを送ることも出来ます。
@<fn>{connection_may_not_close}

//footnote[connection_may_not_close][その場合、上記の例題で使ったサーバでは接続が維持され、次のGETメソッドなどをクライアントがそのまま使えます。大手のニュースサイト等では大量のアクセスがあるといった事情からか、サーバ側からクライアントに、この接続を直ちに切断する同一のヘッダが先に送信されることが多いです。]

==== GET・POST・その他

GETリクエストはサーバからデータ（もしくはリソース）をダウンロード・取得したいというときに使います。
telnetでの例で使ったメソッドでもあります。
GETリクエストではメッセージボディに相当するものは空であることが一般的です。

POSTリクエストはサーバへデータを送る際に用います。
GETの例では空だったHTTPのリクエスト側のメッセージボディに具体的に値をつめこみます。
メッセージヘッダに"Content-Length: 3000"のようにボディの長さを入れておきます。
このときも、WebサーバからはレスポンスとしてHTMLなどを普通に返送するので、
GETリクエストとPOSTリクエストはブラウザ画面だけ見ると差に気づきません。

特定のWebページをリロードする際にブラウザが「フォームを再送信しようとしています」と
警告を表示することがあります。これはPOSTリクエストの結果として表示されたページを送信するときに表示されます。

#@warn(TODO: フォームのリロード時の警告のスクショを貼る)

WebサーバがPOSTに関わるデータを重複して送ると、しばしばおかしな結果になります。
インターネット掲示板で同じ投稿を二度受け付けてしまったり、銀行のWebサービスで振込を二度受け付けてしまったりするのです。
サーバ側で対処する方法もあるのですが、POSTなら2度は再送するメリットは普通あまりないため、
ブラウザでも警告を出すわけです。

なお、GETでは警告は出ませんが、URIで説明したクエリ文字列の仕組みを用いると、
実は少量のデータであれば送れます。こちらではWebブラウザからの警告はないので、
GETのクエリ文字列でWebサーバに保存するデータが変わる場合、
このWebページをリロードするのはまずいことがあります。

仕様で必須（MUST）とされているわけではないですが、
Webサーバの実装のスタイルとしてはGETは「read-only」（読み取り専用）的に動作させるのが一般的です。
クエリ文字列は「検索方法を変える」といった指定にのみ使うべき、と言えると思います。
@<fn>{cachable}

//footnote[cachable][Webでは、レスポンスの高速化のためにキャッシュサーバを使うことがあります。GETリクエストのレスポンスが読み取り専用だとすれば、キャッシュの最有力候補です。ここで、コンテンツに書き込みを行うことをWebサーバが求められていたりすると、キャッシュ出来ません。]

なお、ここではGETとPOSTしか説明しませんが、PUTやDELETEというメソッドもHTTPというプロトコルには存在し、
クライアントからリクエストメソッドとして使用することが出来ます。
Webブラウザの範囲では使うことはあまりありませんが、
後述するREST等、プログラミングの世界でWebを使う場合、他のメソッドが使われることがあります。
@<fn>{naruetsu_again}

//footnote[naruetsu_again][なるえつの梅干し問い合わせの例をHTTPのメソッドに強引に当てはめると、GETではなくHEADというメソッドに相当します。HEADメソッドをクライアントから送られた場合、Webサーバはリソースがあるかないか、といった情報を返しますが、リソースの中身は返しません。HTTPには「そのURIのリソースがいつ更新されたか」「そのリソースのハッシュ値はなにか」といった情報を含める情報をレスポンスヘッダに含めることが出来るため、ウェブスクレイピングのクローラ等が相手Webサーバの負荷を下げるときなどに積極的に検討するべきリクエストメソッドです。]


==== HTTPのレスポンス

HTTPレスポンスは、リクエストに対する応答です。
telnetの例で現れた例をもう一度見てみましょう。

//list[telnet_example_part4_2][telnetコマンドの実行例（4）再掲]{
HTTP/1.1 200 OK
Date: Sun, 06 Jul 2014 06:19:43 GMT
Server: Apache/2.2.23 (Unix) mod_ssl/2.2.23 OpenSSL/1.0.1h
X-Powered-By: PHP/5.5.9
Connection: close
Transfer-Encoding: chunked
Content-Type: text/html

13e
<!doctype html>
<html>

... （以下HTML）
//}

最初の行でHTTP/1.1とあるのは、サーバが実際にHTTPのバージョン1.1で返答した、という意味です。
リクエストの冒頭の行でHTTP/1.1と書いてあれば大抵ここも同じバージョンを返しますが、
まれに異なる返答がありえます。
HTTP/1.1はHTTP/1.0に対する後方互換性維持が仕様上想定されています。
そのため、古い1.0が返答されても仕様違反ではありません。
@<fn>{can_contact_using_09}

//footnote[can_contact_using_09][一部の大手サーバでは現在でもHTTP/0.9風のレスポンスを返してくれることがあります。本稿執筆時に間違って"GET /"と送ってしまったら、同サーバからヘッダなし（0.9なので）でHTMLが返ってきました。後述するHTTP/1.1の新仕様の一つにあたるRFC 7230 Appendix（A.2）には"The expectation to support HTTP/0.9 requests has been removed."とあります。HTTPの旧仕様RFC 2616では期待してたのでしょうが、今は無視してよいようです。]

第一行目のステータス行（Status Line）にはHTTPのバージョンのあと、そのリクエストの簡潔な結果をかえす3桁の数字「ステータスコード」（Status Code）が返され、その後の3桁の数字の説明書きが続きます。
説明書きは数字の定義をそのまま説明したもので、無視できます。

ステータスコードは左端の桁が主要な理由を示しており、残りの2桁でより具体的になります。
いくつか挙げてみます。

 * 200 OK: リクエストで要求されたものが存在したので送りますよ、
 * 301 Moved Permanently: リクエストしたリソースは永久に別の場所へ移動しました。
 * 404 Not Found: そんなリソースは知りません
 * 508 Internal Server Error: サーバ内部でエラーが発生しちゃった！

今回のtelnetの例は"200 OK"とあります。
そして実際、そのリソースに対応するHTMLが返送されています。
該当するWebページが別のURIで示された場所に移動した場合、代わりに301が返答されることになります。
クライアントが指定したURIに誤りがあったりした場合、サーバは単に「そんなの、ない」と言います。
もしサーバがそのタイミングでエラーを出した場合（例えばJavaでサーバを書いてたとするとNullPointerExceptionでクラッシュしちゃった場合）、Webサーバは508で「ごめんなさい」します。

HTTPレスポンスのステータスコードの200番代は「正常」、300番代は「移転」、
400番代は「クライアント側に問題がある」、500番代は「サーバ側に問題がある」という大まかな区別があります。@<fn>{teapot}
@<fn>{joke_rfc_is_ok_to_use}
個別の値もさることながら、Androidアプリ開発ではHTTPレスポンスの大まかな意味がすぐにわかるものなので、知らなければこの区別だけは覚えておくほうが、後々楽です。
個別の数値はRFCを見たり、頻度の多いものは自然に覚えてしまうでしょう。

//footnote[teapot][RFC 2324によればHTTPのステータスコード418 I'm a teapotはティーポットでコーヒーを入れようとしたときに抽出するエラーです。クライアントが容器を間違えているのでありまして、紛うことなき400番代の引き締まった旨味を嗜むことができます。あ、RFC 2324は前述したジョークRFCです。]

//footnote[joke_rfc_is_ok_to_use][もし万が一、本当にステータスコード418 I'm a teapotを返すWebサービスがあったらどうすればよいでしょうか。実はHTTP/1.1の仕様（RFC 7230）では、クライアントに最低でも3桁の先頭の番号だけは理解するよう求めており、仮に残りの二桁で意味がわからなければx00番として解釈してよいと書かれています。ステータスコード400 Bad Requestで処理しろ、とジョークの通じないクライアントはただ判断するだけですから、少なくとも大問題にはならなそうです。]

HTTPではレスポンスヘッダに"Content-Type"というフィールドを入れることで、メッセージボディの中身がどのような種類のデータかを指定できます。
HTMLを返す場合には"text/html"といった文字列が入りますが、ただのプレーンテキストの場合は"text/plain"と指定すれば、Webブラウザがそれを適切に処理します。
@<fn>{charset}

//footnote[charset][この文字列はMIMEメディアタイプというHTTPとは独立して規定された概念です。（RFC 2045, RFC 2046）]

例えばPDF（Portable Document Format）もWebでは一般的に使われます。
そしてHTTPのメッセージボディにPDFを入れることももちろん出来ます。
その場合は"application/pdf"を指定します。
@<fn>{mime_type}

//footnote[mime_type][この"text/html"等の記載をMIMEタイプと呼び、RFC 2046で規定されています。そこで実際に記載されうる文字列の標準はIANAという組織が管理しています。「多くのブラウザ」が適切に処理できるのは仕様と標準が定まっているからです。]

WebサーバはContent-Typeと呼ばれる情報と、実際のデータ（Content）そのものを返します。
Contentは「中身」です。
@<fn>{contents}

//footnote[contents][ちなみに日本語でも「コンテンツ」という表現で使われますが、これはWebページの中身やエンターテイメントのような商品のニュアンスがあります。ここではあくまで送られてくるデータの中身のことで、そういうニュアンスはありません。]

Content-Typeのほかにも多くのレスポンスヘッダがあり、関連するRFCに詳細な規定が書かれています。
またリクエストヘッダにも、同様に多くの情報を入れることが出来ます。
当然、それぞれに目的があります。

例として、すでに登場したTransfer-Encodingについて考えることにします。
Webサーバから送信されるContentが、Content-Typeで記述されているそのままの
形式で送信されているようなら、このフィールドは必要ありません。
例えばHTMLを本当にそのまま返答するWebサーバなら、
このフィールドはレスポンスヘッダには含まれていないでしょう。

実際にはそれだと困るケースもあります。
例えば、HTMLをそのまま転送するのはネットワーク帯域から見て大変無駄なので、
クライアントもサーバもそれは避けたいと思うかもしれません。
その場合、レスポンス内のContentは、何らかのフォーマットで圧縮したほうがよいでしょう。
ただし、クライアントがその圧縮された内容を解凍できる必要があるのはもちろんです。

この「圧縮」の例では、クライアントがまず「圧縮きぼん」と
クライアントヘッダ（Accept-Encoding）でサーバに伝えてあげる必要があります。
より具体的には、クライアントは自分が対応できる圧縮方法を指定します。
HTTP/1.1ではcompress, gzip, deflateの3種類が規定されています。
複数指定可能です。

その後、Webサーバはもしその圧縮方法でデータを転送できるようなら、圧縮して転送します。
このとき"Transfer-Encoding: gzip"などと、圧縮した方法は必ず送信してきます。
クライアントはそこを読んで「そうか、それを使ったか」と理解し、
Contentを適切に解凍します。

無理なら、Webサーバは無視して圧縮しなくて構いません。
その場合はTransfer-Encoding行はないはずですので、クライアントは混乱しません。
@<fn>{vary_field}

//footnote[vary_field][「え、それ先に知りたくね？」というケースではVaryという別のレスポンスヘッダフィールドを見ることになるでしょう。]

さて、本章のtelnetの事例で実際に発生したのはこの圧縮ではなく"chunked"という
別のものです。これもRFCには規定がありますが、ざっくり説明します。

HTTPのリクエストやレスポンスに、「終端記号」に該当するものがないことに気づいた方もいるかもしれません。
終端がわからないと、HTTPの性質上、クライアントがContentを受信中にサーバとの接続が切れた際、
そのコンテンツが完結しているのかしていないのか、区別する手段がありません。

HTTPでは終端器号がないかわりに、Content-Lengthという別のヘッダフィールドで、
文字列の長さを送信することで終端を暗示できます。

しかし、ヘッダにContent-Lengthを入れるのが難しい場合があります。

静的ファイル一つ（index.html）であればまだしも、
例えばニュースが動的に埋め込まれる場合にはこの計算は
不可能でないにしても、非常に面倒になります。

そのような動的なコンテンツ生成をする場合、
きっと実際にしばしば行われるのは、
まずWebサーバがヘッダを送信した後、
後続のHTMLを随時作りながら送信するというスタイルでしょう。
Content-Lengthはこの実装の妨げになります。

もうひとつ考えられるのは、
HTTP上で動画のような巨大なデータを送信する場合です。

ヘッダにContent-Lengthを埋め込むのが難しい時には
"Transfer-Encoding: chunked"を使うことが出来ます。
@<fn>{about_chunk}
この指定をした場合、Contentには
「次に配送するデータのサイズ」
を先に記述し、その後にそのサイズのContentを実際に送ります。
送りたいものが全て送れたら、Webサーバは0を送ります。
0が言ってみれば「終端」を表すわけです。

//footnote[about_chunk][chunkには「ぶつ切り」という意味があります。]

仮に途中でネットワークが切断されてもこれならどこまで送信されたか、
あるいは「送信されしきったか」が分かります。
おまけで、HTTPにはクライアントがコンテンツの一部だけWebサーバに要求する方法も定義されています。
「受信の再開」みたいなことがプロトコルレベルで出来るわけです。
@<fn>{apache_uses_it_by_default}

//footnote[apache_uses_it_by_default][これまでの例では本当はchunkedを使うまでもないはずなのですが、Webサーバによっては、特別に指定をしない限りはContent-Lengthではなく"Transfer-Encoding: chunked"を標準で使うケースがあるようです。]

HTTPにはこの他にもたくさんのヘッダが定義されていますが、
本章での説明はここまでにします。
関連するRFCを紹介しますので、興味があればそちらを読んでみてください。
ここでは「HTTPは大体こういうプロトコルで、実は奥が深い」というところが分かっていただければ最高です。

#@# ==== 演習: Android アプリからWebサーバにアクセスしてみよう

#@# さて、ここでは実際にAndroid経由でHTTPアクセスをしてみましょう。
#@# ここでは@<code>{java.net.HttpURLConnection}を用いることにします。

#@warn(ネットワークの章でWebサーバへアクセスする事例は終了している可能性が高い。要調整)

#@# ====[column] DefaultHttpClientとAndroidHttpClient について

#@# HTTPアクセスを行うライブラリは他にも@<code>{org.apache.http.impl.client.DefaultHttpClient}や
#@# @<code>{android.net.http.AndroidHttpClient}といったライブラリが紹介されることがあります。
#@# しかし本稿ではそれらの理由はおすすめしません。
#@# 現時点でこれらの実装にはバグが多く、今後もメンテナンスされる見込みがないと考えられているためです。
#@# なお、非常に古いAndroidのバージョン（2.2）では@<code>{java.net.HttpURLConnection}にバグがあったため、
#@# それらの古いバージョンでは注意が必要です。
#@# 
#@#  * 参考: Android Apache HTTP Client と HttpURLConnection どっちを使うべき？ @<href>{http://y-anz-m.blogspot.jp/2011/10/androidapache-http-client.html}@<fn>{this_is_also_old_article}
#@# 
#@# //footnote[this_is_also_old_article][記事の公開2011年10月4日に公開された点も出来れば]
#@# 
#@# ====[/column]

==== curlコマンド

telnetコマンドを使ってみましたが、正直言えば、これはだいぶ不便です。
@<fn>{shutdown}
例えばPOSTリクエストを送る場合には手で入力するのはさらに難しくなります。
繰り返し試しつつ、少しずつ内容を変更する、といった場合にもただ面倒なだけです。

//footnote[shutdown][telnetで一つ一つの文字列を丁寧に入れてもサーバの機嫌が良くなったりはしませんし。むしろ人間の入力は遅いので、タイムアウトでサーバから一方的に接続を切断されたりします。]

一方Webブラウザで結果を見ると、本物のWebページを見ていることになりますが、telnetのようにその下で何が起きているかを把握はしづらくなります。
やはり、ある特定のHTTPリクエストを発行したい、という要望を叶えるのは難しいです。

中間の対策として、しばしば使われる別のコマンドラインツールとして、
curl（cURL）があります。
これはいろいろなHTTPリクエストをサーバに送って見る上ではかなり便利です。
@<fn>{curl_is_really_useful}

//footnote[curl_is_really_useful][本当はAndroidアプリで取ってきた例を上げたほうがAndroidの教科書らしいんですけど、本章では時間の都合もあって省略します。いろいろ試す場合にそのたびにActivityを作ってアプリを起動して、とやるより、単にcurl一行でデータ取ってきて、状況に応じてPOSTリクエスト等を送るほうが、Webサービスの様子を調べるほうが効率はよいような気がします。]

まず、curlで@<href>{http://techinstitute.jp/}というURIにGETリクエストを送る例を示します。

//emlist[curlのGET実行例]{
$ curl http://techinstitute.jp/
<!doctype html>
<html>
<head>
<meta charset="UTF-8">

... （HTMLどびゃー）
//}

これですとヘッダがわかりませんが、"-v"オプションをつけると、ヘッダの内容も見られます。

//emlist[curlのGET実行例。今回はリクエストヘッダとレスポンスヘッダを見る]{
> curl -v http://techinstitute.jp/
* About to connect() to techinstitute.jp port 80 (#0)
*   Trying 157.7.156.136...
* connected
* Connected to techinstitute.jp (157.7.156.136) port 80 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.26.0
> Host: techinstitute.jp
> Accept: */*
> 
* additional stuff not fine transfer.c:1037: 0 0
* HTTP 1.1 or later with persistent connection, pipelining supported
< HTTP/1.1 200 OK
< Date: Wed, 09 Jul 2014 07:48:07 GMT
< Server: Apache/2.2.23 (Unix) mod_ssl/2.2.23 OpenSSL/1.0.1h
< X-Powered-By: PHP/5.5.9
< Transfer-Encoding: chunked
< Content-Type: text/html
< 
<!doctype html>
<html>
<head>
//}


次にPOSTリクエストで、@<href>{http://127.0.0.1:8000/submit}というURIに対して、
まるでHTMLのフォームを入力したかのように"message=Sample Message"というデータを送信する例を示します。

//emlist[curlのPOST実行例]{
$ curl -F "message=Sample Message" http://127.0.0.1:8000/submit
//}

特に後述する「プログラマブルな」Webでは大変重宝します。
@<fn>{facebook_maripo_book}
ここではcurlコマンドについての詳細な説明はしませんが、興味があればぜひオンラインマニュアル等を参照してみてください。

//footnote[facebook_maripo_book][curlコマンドは、Webアプリケーション開発に関する記事や書籍でしばしば目にする有名なツールです。例えば郷田まり子著『facebookアプリケーション開発ガイド』でも、Facebookと連携するWebアプリケーション作成の際にcurlを用いる方法を紹介しています。]

==== Cookie

HTTPはもともと「ステートレスなプロトコル」と言われます。
仕様の中に「前回の状態をサーバは覚えておいてね♪」と要求する方法がない、という意味です。

具体例を挙げてみましょう。
江戸時代からあるテイクアウト専用のハンバーガ屋「ステートレス・バーガー」を考えてみます。
普通の客は500円を払って即座に生成されるハンバーガーをGETして帰ります。

ここで江戸時代から付き合いのある下町の旦那がやってきます。
お金がありませんので「ツケといてくれ、旦那」と伝えます。
店員は困惑しつつ「わかりました、次回おねがいしますね」といいつつ、ハンバーガーを一つ渡します。

次にその旦那はしっかり1000円持ってきて店に渡します。

しかし、ステートレス・バーカーの店員は1000円もらったのでハンバーガー二つを注文されたものと勘違いします。

ハンバーガーを2つもらって旦那は困惑します。
「おい、おれの顔を覚えちゃいないのかい……？」

もう少しまともな例を挙げましょう。

例えばGMailのようなWebメールのアプリケーションでは、最初にログイン操作を行います。
HTTPで言えば、POSTメソッドでユーザ名とパスワードを送るイメージです。

さてWebサーバーはユーザ名とパスワードを受け取って、正しいユーザーだと理解したので、
「あなたは正しいユーザーです！」とサーバもブラウザも大喜びです。

さて次にユーザーがしたいのは自分のメールチェックです。
そこで、GETメソッドなどでメールの一覧に対応するURIへアクセスしようとするでしょう。

ログイン画面に飛ばされました！！

自分の顔を覚えてくれない老舗のテイクアウト専用ハンバーガ屋と、
Webメールの無限ログイン画面問題、根っこにある問題は同じです。
今までの説明の範囲では、Webサーバはクライアントに関する情報をうまく覚える仕組みがありません。

しかし実際にWebサーバを介してアクセスすると、
多くのWebサービスでは、ユーザ名とパスワードなど、いろいろなものをWebサーバが記憶しているように見えます。
特に、ブラウザを閉じてもそれらが残っているのは、驚きです。
どうなっているのでしょうか。

この大方の欲求に対処するのがCookie（HTTP Cookie）と呼ばれる仕組みです。
CookieはWebサーバからブラウザに「このkeyとvalueの組み合わせを覚えておいてください」
という意味のSet-Cookieレスポンスヘッダを送ります。
Webブラウザは保存していたCookieを次の接続時にCookieヘッダとしてリクエストヘッダに埋め込みます。
この仕組みを双方が了承することで、ステートレスなHTTP上でWebサーバとクライアントの間で
状態を維持することが可能になります。
@<fn>{cookie_rfc}

//footnote[cookie_rfc][RFC 6265が参照できる最新の仕様ですが、『HTTPの教科書』p161によるとこのRFCの通りには現状の実装は動作していないとのことです。]


==== HTTPのRFC

本章執筆時点（2014年07月）で、HTTPには0.9、1.0、1.1の3つのバージョンがあります。
IETFのHTTPbisワーキンググループでは現在2.0の仕様策定がされており、最終段階にあるとのことですが、
「そもそもHTTP 2.0はそのまま破棄して次の仕様を作り直すべきだ」と主張する人々もいるため、完全に仕様となるまでは若干注意が必要です。
@<fn>{http20_thrown_out}

//footnote[http20_thrown_out][英語ですが、例えば @<href>{http://www.phoronix.com/scan.php?page=news_item&px=MTcwMTA} などを参照してください。]

HTTP/0.9と1.0については省略し、HTTP/1.1について考えます。
HTTP/1.1は当初、1999年に発行されたRFC 2616を拠り所として15年使われてきました。
しかし曖昧さや現在のWebにそぐわない仕様が盛り込まれていることはよく知られていました。

2014年6月に、このHTTP 1.1の仕様が15年ぶりに改定されました。
現在ではその内容が下記のRFCとして公開されています。

 * RFC7230: Message Syntax and Routing
 * RFC7231: Semantics and Content
 * RFC7232: Conditional Requests
 * RFC7233: Range Requests
 * RFC7234: Caching
 * RFC7235: Authentication

なお、関連して続く4つのRFCもHTTP/1.1の新しい仕様として参照されることがあります。

 * RFC7236: Authentication Scheme Registrations
 * RFC7237: Method Registrations
 * RFC7238: The Hypertext Transfer Protocol Status Code 308 (Permanent Redirect)@<fn>{experimental_rfc7238}
 * RFC7239: Forwarded HTTP Extension

//footnote[experimental_rfc7238][このRFCだけexperimentalです。ステータスコード301も本文で述べた通り"Permenanent Redirect"なのですが、その際にサーバがPOSTリクエストをGETリクエストに書き換えてしまうといった、当初の想定と異なる実装が多いので、再度厳密に定義したものです。ただ、知らないサーバのほうが多いので、運用に注意しつつ試す、という意味合いが込められているようです。気になる方はRFC本文を読みましょう]

RFCは同じ分野で新しい仕様を必要とした場合、過去のRFCをobsolete（廃止）扱いとすることで新しい（番号の大きな方の）RFCを利用するよう促します。
古い番号のRFCが指し示す内容が書き換わるわけではなく、新RFCの方に廃止扱いのRFCの番号が列挙される仕組みです。

今回の改定RFCで、HTTPの新しいバージョンが定義されたわけではありません。
HTTP/1.1と呼ぶとき、今後はRFC 2616ではなく上記の一連のRFCのみを参照するようにしてください。

なお、執筆時点（2014年7月）では「HTTP RFC」とGoogle検索すると、最初にRFC 2616が検索トップとして表示されたりするため、より注意が必要です。

//image[search-result-for-http-rfc][HTTP RFCの検索結果。サッカーワールドカップ 2014の最中です]{
//}

一連のRFCの策定にも関わっているMark Nottingham氏は自身のブログ記事"RFC2616 is Dead"（RFC2616 は死んだ）
@<fn>{mark_nottingham}で、
「RFC2616は使わないでください。ハードドライブ、ブックマークから削除し、
印刷されているなら全て燃やしてしまうかリサイクルに回しましょう」とまで書いています。 

//footnote[mark_nottingham][@<href>{https://www.mnot.net/blog/2014/06/07/rfc2616_is_dead}]

バージョンが変化していないため、混乱が助長されるのではないか、という考え方も出来る気がします。
しかし筆者がざっと眺めた印象では、そのような懸念を払拭するほどに丹念に作られたRFCであると感じられます。

上記のRFCは、過去の1.1の仕様の曖昧さを排除し、明らかに誤りだった点について今後そういった実装を行わないよう釘をさしつつ、
過去のクライアントやサーバが間違った動作をしても対応できるよう、注意が払われています。
特に、これまで10年以上に発生してきた問題の背景とHTTP/1.1における対策に説明が費やされている点が素晴らしいと筆者は感じます。

また、各新RFCには、RFC 2616からの変更点や背景が説明されおり、差分を知る上でも十分な配慮がなされています。
徹底的に考えられているという意味で、大変すぐれたRFCなのではないかと感じます。
全ての文面を確認したわけではありませんが、「堅牢性原則」の鏡のような内容です。
@<fn>{robustness_principle}

//footnote[robustness_principle][「送信するものに関しては厳密に、受信するものについては寛容に」という通信における原則のことで「ポステルの法則」と呼ばれたりもします。ここでは「新しい実装同士では厳密に、古い実装に対しては寛容に」といったニュアンスで使っています。ちなみに実践するのは大変です。]

RFCはそもそも何も知らない人がゼロから読む「教科書」ではありませんが、
本章を理解できる読者ならば、新HTTP/1.1の内容は、HTTPに限らずよい勉強になるだろうと筆者は思います。
@<fn>{new_rfc_is_good}

//footnote[new_rfc_is_good][曖昧さがあるRFCというのは読んでいて非常に辛いものですが、ここまで広範に使われているWebの屋台骨を綺麗に作りなおしただけあって、本当にすごいですねこれ。はい。]


== めんどうくさいWeb

これまで見たWebの一連の技術（HTTP、URI、HTML）は、一見するとシンプルで問題も少なそうです。
しかし詳細に見ていくと、一歩間違えると危険な状況に直面する状況が山ほどあります。

例えば以下のHTTPレスポンスを見てみます。
改行コードについては明示的に[CR]や[CR][LF]と明示しました。
@<fn>{from_tangled_web}

//footnote[from_tangled_web][『めんどうくさいWebセキュリティ』のp60からの引用です。]

//list[header_injection_example1][ヘッダインジェクションの例]{
HTTP/1.1 200 OK[CR][LF]
Set-Cookie: last_search_term=[CR][CR]<html><body><h1>Hi![CR][LF]
[CR][LF]
Action completed.
//}

特定のブラウザでは、これは以下のように見える可能性があります。
@<fn>{previous_section}

//footnote[previous_section][混ぜるのは意図的にしろ、CRとCRLFを間違えるなど人間ならやりがちです。前章のtelnetの例に至っては、わかっててやってます。]

//list[header_injection_example1_2][ヘッダインジェクションの例で改行を間違えて展開した場合]{
HTTP/1.1 200 OK
Set-Cookie: last_search_term=

<html><body><h1>Hi!

Action completed.
//}

このように解釈してしまった場合、本来意図した"Action completed."に変わって返答内容の先頭に想定外のHTMLが挟まったように見えます。
このようなWebブラウザがあったとすれば、それは「ヘッダインジェクション」「ヘッダスプリッティング」といった名前で呼ばれる立派な脆弱性を抱えています。

HTTP 1.1の仕様と言えるRFC 2616は1999年に書かれました。「ドットコムバブル」の頃です。

それから時代と共にWebが進化する過程で、すでに述べたとおりWebも新しい用途に頻繁に使われるようになりました。
また、そもそものRFC 2616では現在ではあまり使われないか、悪用されると上記のような脆弱性
の元になるような機能があり、さらに特定のケースでの曖昧な記述が、
Webサーバやブラウザの挙動の違いを引き起こしました。
@<fn>{strict_web}

//footnote[strict_web][ちなみになんでもかんでも厳密であればいいのかと言われれば、普及の観点から言うとそうでもないようです。HTML4がぐっだぐだだったことから、マークアップ言語の厳密性を書き手に矯正するXMLベースのXHTMLという仕様が生まれました。当初はこれで決定打になるかと思いきや、今でもHTML 4.01が使われ、Web上ではあまり流行りませんでした。本章担当者の意見としては「書き手に厳密性を求めたら角をためて牛を殺すようなもの」という印象を持ちます。HTML5はHTML 4.01のように緩くHTMLを書けるように見えますが、マークアップ言語のゆるい部分について、Webブラウザ側の解釈ルールが実は厳密になっている、ということだそうです。XHTMLは今でもepubのような用途で使われているようです。ちなみに前章のtelnetの例でもCRLFを送るべき所でCRを送っていますので、「厳密」なサーバなら取り扱ってくれないでしょう。]

一般的に言えば、脆弱性の問題は古いライブラリやそれを使うアプリには残りがちで、一方HTTPのリクエストやレスポンスはユーザから直接見えません。
利便性を追求するために間違った挙動を許すと、それが見えないところでフィッシングサイトなどを手伝う結果になります。
上記の「ヘッダインジェクション」の脆弱性は、対応のまずいWebブラウザでは一切の警告が表示されることなく、全てのHTMLを攻撃者が書き換えられる可能性を意味しています。
当然、現在の最新のWebサーバやブラウザでは対応が行き届いている、はずです。

上記の例ではそもそも、仕様で認められないCRLF以外の改行コードを改行と認識しているから起きる問題です。
一方、たとえ仕様通りであっても、ユーザをトラブルに導きかねない状況はありえます。

一見してシンプルそうなURIについて考えてみます。
例えば@<href>{http://xn--t8jx73hngb.com/}と書かれた時に人間がこのURIが馴染みのあるWebサーバのものかそうでないかを判定できるでしょうか。
@<fn>{punycode}

//footnote[punycode][@<href>{http://お名前.com}をpunycodeを使って書いてみました。試したブラウザではpunycodeを日本語名に自動変換してくれましたが、常にそのように守ってくれるかどうか、筆者は確信が持てません。]

現在Webは世界中で利用されていますから、全ての端末にフォントがあるとは限りません。
フォントがない状態で豆腐が表示されるのを回避するためにpunycode込みのURIが表示されても、
正規のWebサイト化フィッシングサイトかを区別するのは、結構難しいように筆者には思えます。

例えば日本語を読めない人が日本語ドメインのWebサイトとそれに似たフィッシングサイトを見分けるにはどうすればよいでしょうか。

インターネット上のどんな場所でもUTF-8を使えばいいんじゃないか、という意見もあるのですが、
多国語の読めない文字は、脆弱性と組み合わさると結構悲惨です。
何が正しい応答かすらわからないわけで。

Webサーバと通信しているクライアントアプリケーション（Androidアプリも含む）は、
こういったサーバサイドの問題に対して対策をとっていないとき、ユーザへ二次被害を与える可能性があります。
Webサーバ側の脆弱性について本章ではほとんど触れません。
しかしそういったことを参考程度に覚えておくと、Webサーバが攻撃されて悪意のあるデータがHTTPレスポンスに流された時などに、身を守れる「かも」しれません。

最低でも、自分でHTTPクライアントを自作しよう、とはなるべく思わないほうがよいでしょう。
併せて、使うならなるべく安定したライブラリを使う必要がある点も、ここで再度確認しておきましょう。

RESTでHTTP GETを使って値を取るくらいであればよいのですが、
もし自分のサービスが（WebViewなどを通じて）Webサービスと密に結合している場合、
古いバージョンのAndroid端末をサポートから切る、という判断も必要になることがあります。


== プログラミングインターフェースとしてのWeb

これまで説明してきたとおり、Webは当初、人がコンピュータにアクセスして「ハイパーテキスト」を閲覧するものでした。

しかし現在のWebはそれだけにとどまりません。
Webサーバを介して人を介さずにコンピュータやアプリ同士が通信を行い、
データをやりとりしている世界もまたWebです。

本節ではHTTPやURIという中心的な仕組みはそのままに、
コンピュータ同士が通信する場としてのWebを考えていきます。
当然、この「コンピュータ」には読者が作るであろうAndroidアプリも含まれます。

=== Web上でのコンピュータ同士のやりとり

すでに説明したとおり、HTMLは人が読む「ハイパーテキスト」を記述した言語です。
つまり、そこには人が読める文章があり、リンクがあります。
見栄えを整えるため、CSSのように文章全体、Webページ全体を装飾する必要もあります。

しかしコンピュータ同士であれば、通信する内容は単純な「データ」であるほうが便利です。
人間向けの装飾は邪魔かもしれません。

天気予報の情報をWeb上で収集する例を考えます。
人間が天気予報を見る場合、特定の日付・時間帯の天気、気温、湿度が図表で表示されていると、「明日は午後から台風か」とひと目で分かります。
もし、ある特定の地方を見たいのであれば、地図の上に、各地域の情報が載っているほうがより使いやすいでしょう。
世界地図上に天気のアイコンが並んでいれば、南極の気温と日本の気温を混同することはありません。

//image[weather-1][ある日の東京の天気]{
//}

では、アプリがその情報を自動的に取得する場合はどうでしょうか。

コンピュータが@<img>{weather-1}のような画像や文字列から情報を取得するのは、不可能ではないものの、大変面倒です。

では、次のようなデータであればどうでしょうか。

//footnote[we_should_know_format][もちろんこのフォーマットのルールが分かればです。すぐ説明しますがJSONというフォーマットのデータの一部をとって来ました。]

//list[weather_json][ある日の東京の天気]{
  "forecasts": [
    {
      "dateLabel": "今日",
      "telop": "曇時々雨",
      "date": "2014-07-11",
      "temperature": {
        "min": null,
        "max": {
          "celsius": "34",
          "fahrenheit": "93.2"
        }
      },
      "image": {
        "width": 50,
        "url": "http://weather.livedoor.com/img/icon/10.gif",
        "title": "曇時々雨",
        "height": 31
      }
    },
//}

@<list>{weather_json}のような形式の場合、日付やそれに対応する天気がどうやって表記されているかさえ分かれば、
プログラムからデータを取るのは比較的容易いでしょう。

特にAndroidアプリのようなケースでは、HTMLで人向けに提供される画像データをダウンロードして、UIにそのまま表示するとは限りません。
比較的狭いスマホ画面上で適切な「天気予報」レイアウトを構築する場合、その画像があるよりは、単に「晴れ」と書いてあったほうが、解釈は楽です。
人がWebブラウザで見るためのレイアウトまで考慮されたHTMLよりも、
機械が読み取りやすいデータ形式で送ってくれたほうが、それを取りに行った側のアプリでの作業は軽減されるでしょう。

HTTPでは、WebサーバがContent-Typeと呼ばれる情報を返して、クライアントに返答するデータの種類を返答します。
HTMLを読む場合にはContent-Typeは"text/html"ですが、HTMLではなく別の形式を指定することが出来ます。
PDFの例はすでに示しました。

ここに、コンピュータが判別しやすいデータフォーマットを指定してあげれば、HTTPの仕様に基づいてそのまま情報をやり取りできます。

Webは人が情報を読むためでなく、コンピュータ間でスムーズなデータ交換をするためにも使えるのです。
この場合、HTTP（@<b>{Hyper Text} Transfer Protocol）は、ハイパーテキストを送るという当初の役割を超えて利用されることになります。


=== XML、JSON

コンピュータ同士のやり取りで便利なフォーマットとして、現在では特にXMLとJSONが使われることが多いです。
例えば@<list>{weather_json}はJSONフォーマットの一部を抜粋したものです。
この他のフォーマットも使われることがありますが、大手のWebサービスで提供されるフォーマットではこれら2種類を見ることが引き続き多いと予想されます。

アプリケーション開発では、それらのフォーマットで送信されてきたデータをアプリ内で解析するか、
逆にアプリ内のデータをそれらのフォーマットに変換して送信します。

ライブドアが提供する天気予報APIを使用するcurlコマンドを以下に示します。

//emlist[一行でどばー]{
$ curl http://weather.livedoor.com/forecast/webservice/json/v1?city=130010

.. (天気予報のJSONデータ)
//}

//image[weather-2][一行でどばー]{
//}

この時点で人間には「これが、天気予報？？」と思わせる出力ですが、Androidプログラム上でJSONパーサライブラリ等を使えば、Java内のListやMap等のオブジェクトに変換することが出来ます。
@<fn>{jq}

//footnote[jq][curlでデバッグをしているとき、表示をこのままに中身を解析することは実務ではあまりありません。いや読めないし。JSONやXMLをフォーマットしてコマンドライン上で読みやすくしたり、加工してレスポンスのこれまたJSONやXMLを自動生成したりすることがあります。本章筆者の場合ですと、JSONに対してはjson_reformatやjqといった別のコマンドラインツールに上記のデータを与えて、人が読めるように整形されたJSONを見ることが多いです。XMLでも同じようなコマンドがあります。]

XMLはよりHTMLライクなデータフォーマットです。
本質的ではないのでここでは一旦省略します。


==== REST（Representational State Transfer）とRESTful

HTMLをWebブラウザで見る、という方法が伝統的なWebでした。
しかしAndroidプログラマにとってしばしば大事なのは、プログラミング上でもWebをそのまま「インターフェース」として使う方法です。
このとき、しばしばRESTという用語を聞くことになるため、言及しておきます。
@<fn>{not_important}

//footnote[not_important][忙しい人はここは飛ばすことをおすすめします。Webはクライアントから見ると単に「使う」ものなので、RESTとRESTfulのサービスを選ぶ権利はほとんど与えられていません。]

まず、しばしば「RESTful」と呼ばれることもある、狭義のRESTについて説明を試みます。@<fn>{restful}

//footnote[restful][この表現は「がんばって書いたけど正しいという自信もない」ことを示しています。]

RESTはもともと2000年にHTTPプロトコルの筆者の一人であるRoy Fielding博士の博士論文から始まった概念です。

Webにおいて大事なのはHTTP、URI、HTMLです。
ここではHTMLとそれに似ていてコンピュータが解釈しやすいXMLを同一視してしまいましょう。

HTTPはGET/POST/PUT/DELETEというメソッドを仕様に持っています。
これがなんとなく、データベースの理論で出てくるCRUD（Create, Read, Update, Delete）に似ています。

見方を変えると、Web上に存在するリソースに対する「新規作成」「取得」「改変」「削除」に関与出来る、
基本的な動詞がHTTPに揃っています。
「Web上のリソースを操作する関数名が、HTTPのメソッドにすでにある」ということになります。
そういえばJavaでもオブジェクトに付属する関数の類をメソッドと呼びますね。
@<fn>{post_is_not_update}

//footnote[post_is_not_update][PUTがCreate（作成）、POSTがUpdate（改変）であるかのような説明ですが、そうとも限りません。そもそもCRUDとHTMLの4メソッドは似ているものの、1対1で対応するわけではなく、RESTの実装方法には大きな幅があると言われています。]

URIというのはHTML（XML）というリソース（データ）の場所を一意に識別するための手段です。
リソースの場所をURIに記述して、それをどうしたいかの「動詞」をHTTPリクエストとすれば、その動作の結果がHTTPのレスポンスに対応します。

例えば、天気予報というリソースを提供するWebサービスがあったとします。
天気予報サービス上のリソースというのは天気データそのものです。
地方に応じた天気を別のURIにマッピングしているとして、それぞれの地方、日付の天気予報というリソースをURIで一意に認識できるように作ることが出来ます。
たとえば@<href>{http://weather.example.com/earth/japan/tokyo/taito-ku/2015/01/10}なんてどうでしょうか。

そこにGETメソッドでアクセスすると、該当する日付の天気予報データがXMLで返ってきます。
@<fn>{json_may_be_good}

//footnote[json_may_be_good][URIのquery要素で"format=json"と書いてJSONが返ってきたら素敵そうです。]

プログラムのメソッドや関数は成功か失敗かは戻り値で返答することがしばしばです
ところで、HTTPにはステータスコードでまさに成功、失敗を示す番号があります。
リソースが別の場所に移動した時のためのステータスコードまで世界中で一意に定義されており、
すでに仕様でまとまっているので、Webサーバやクライアント側で新しいクライアント・サーバのソフトウェアを作り直す必要はありません。

もしあなたが管理者なら、新しい日付に対応するURIにPUTしてあげれば、翌日の天気予報データをそこに置けます。
古い天気は、DELETEで消してもよいです。
過去の天気は確定したのだから、確定した天気情報を（PUTかPOSTで）更新してあげてもよいかもしれません。

ユーザが「どこに台東区の2015年3月12日の天気予報データあるかなぁ」と思うことは基本的にありません。
URIが変わらないからです。
この思想を大事にしてpath部分を設計すると、URIはいつも特定の場所の特定の日の天気を保持し続けることができます。

URIで場所を指定するということはつまり、インターネット上でリソースを長時間保持するための巨大な木構造が1つあるということです。
天気予報サービスと書籍目録サービスがあったとして、お互いに混乱を与えることはありません。
ユーザも、ある場所にアクセスすれば同じリソースの情報があると、自信を持てます。

特にGETメソッドは、副作用のない純粋な関数にも大変似ています。
そもそもHTTPはステートレスという説明をしました。
次に呼び出しても同じリソースについての情報がいつも返ってくるのです。
ついでに言えば、この方法でデータを保存しておくと、Webサーバは同じデータをキャッシュに置くときにも、非常に効率良くデータを管理できるでしょう。
@<fn>{safe_idempotent_cachable}

//footnote[safe_idempotent_cachable][RFCには各HTTPメソッドについて「Web上のリソースを変更するかしないか」（Safe）「操作を何回行ってもリソースに対する結果が同じになるか」（Idempotent）「キャッシュ可能か」（Cachable）の3つの視点で説明が行われています。本章では説明していない、プロキシやキャッシュサーバのような存在がHTTPのやりとりに絡むと、特に意識したくなるポイントです。]

このようにURI、HTTP、HTML（XML）を解釈した場合、これまでのWebが少し違った形で見えてきます。
現状のままで、プログラミングのシンプルなインターフェースにも使えるのではないか、と考えられるのです。
しかもHTTPやURIの仕様は、RFCやその他の標準という形で、すでに世界中で受け入れられています。
この部分について、わざわざ新しいインターフェースを仕様策定する必要はありません。

サーバとクライアント双方のアプリさえサポートしてくれれば。

えーと、なんとなく、HTTPとURIがプログラムの関数名と仮引数っぽくなって、見えて来ませんか？
見えてこないですかね。説明が悪いですかね。

ともかく、WebにおいてHTTP、URI、HTML（XML、JSON）を真面目に定式化すると、
そのまま既存のプログラムと整合性が高い解釈が出来るのでした。
これをREST（Reperesentational State Transfer）と呼びます。
@<fn>{roa}
@<fn>{restructured_text}

//footnote[roa][RESTfulなWebサービスのようにリソースを中心に据えてソフトウェアの構造を考えるアプローチを「リソース指向アーキテクチャ（Resource Oriented Architecture）」と呼ぶ向きがあります。実際にはRESTful Webに関わる以外でこの表現を見ることはまれです。同一視する説明も目にします。]
//footnote[restructured_text][「れすと」と呼ぶ時、reStructuredTextという別の技術用語の短縮形であることがありますが、別物です。]

というところまで書いた後、世の中のRESTの例を見てみます。もう一度先ほどのcurlの例をどうぞ。

//emlist[一行でどばー]{
$ curl http://weather.livedoor.com/forecast/webservice/json/v1?city=130010

.. (天気予報のJSONデータ)
//}

city=130010はまだいいんだけどいつの天気予報のデータとか、一切指定できませんね。XMLも吐きませんね。

世の中の「RESTのWebサービス」というと、上記で説明したほどHTTPやURIの仕組みをうまく使いません。
データの取得、作成、削除にHTTPのそれぞれのメソッドを使うわけではなく、GETとPOSTだけしか許さないことが普通です。
また、そもそもURIに@<href>{http://example.com/some/data/update}といった風に、暗黙のメソッド名が入ってしまったりします。
HTTPに該当するメソッドがあるとか、そういうことは考えません。
@<fn>{we_will_do_that}

こういったRESTを、「REST風」のWebサービスと呼んだりします。
実際には「風」とついていてもいなくても、この「ゆるい」ほうであることが多いです。

//footnote[we_will_do_that][本章後半で、RESTfulで「ない」Webアプリケーションを作ります]

そもそも、元々のRoy博士の論文をベースにした「REST」を元にしても、実際に意味されるものの詳細は人によって異なることがあるようです。
今回「試みた」説明も、厳密なRESTful愛好家からすると誤りを含むものである可能性があります。

また、Androidアプリから見た場合、RESTインターフェースの純粋さはあまり興味を引かないかもしれません。
大手Webサービスを利用する場合、RESTかRESTfulかを選択する権利が通常ありません。

一方、Webサーバを実装したり、WebサーバとAndroidのクライアントをまたぐサービス全体を設計する際には役立つ可能性のある概念です。
特に、大量のリソースをツリー構造に並べることでシステム設計がシンプルになるのなら、RESTfulなアーキテクチャを真面目に捉える価値があると筆者は考えます。
@<fn>{cookie_and_rest}

//footnote[cookie_and_rest][RESTfulと呼ばれた場合ステートレスが基本ですので、Cookieを使ったセッションは非推奨のようです（@<href>{http://en.wikipedia.org/wiki/Resource-oriented_architecture}）。実際、ログインが存在するWebサービスの場合、ログイン前後でURIが指し示すリソースが変わってしまうことがあります。あるURIにユーザがアクセスしたとき、ログインが必要なのでステータスコード302をWebサーバが返したりすれば、それはそのリソースに基づいて返答があったわけではないという意味で、RESTfulではありません。うーん、厳密に適用するのは結構難しいですよ、（ここにRESTfulを示すurnを入れる）]

=== ウェブスクレイピング

XMLやJSONのようにアプリで簡単に処理出来る形式でデータを、Webサーバ側が提供してくれない場合があります。
そのような場合に、人が読むWebページ（HTML）からパターンを抽出して、
クライアント側が本当に欲しい情報を取り出すことを「ウェブスクレイピング」と呼びます。
また、そのような目的でWebサーバを巡回するソフトウェアを「クローラ」などと呼びます。

この手法自体は大変一般的です。
本章で説明した当初のWebからよく行われていました。
Web検索などで使われるのは当然ですし、アプリを開発する上でもしばしば便利と感じることがあるでしょう。
達成したいアプリケーションの性質上必須であることもよくあります。

例えば、人気テーマパークの混雑状況を調べるアプリを考えます。
@<fn>{warned}

//footnote[warned][すぐに後述する通り、この方法には技術的なもの以外も含めて、前もって知っておくべき事柄がいくつかあります]

来場者や来場を計画している人が見るためのHTMLで書かれたWebサイトはあっても、XMLやJSONによるデータフォーマットを提供していないことがあります。
そこで、来場者が見るためのWebサイトのHTMLを解析して機械的に解釈できるデータに変換します。
特定のタグの中にある「混雑状況: スッカスカ！」の「スッカスカ！」の部分から
「混雑度が20%未満の場合こう表示されるのだな」と推測するなどして、
アプリのデータとして利用するのです。
ここが「混雑状況: 激混み！」に変わったら、アプリは自動的にそれを検出し、
Androidの通知フレームワークを介してユーザにそれを教えられるわけです。
便利そうですね。
@<fn>{weather_is_same}

//footnote[weather_is_same][天気予報の例でも、REST風APIがない場合には応用出来る考えです。「今日は晴れでしょう」という文字列から「晴れ」を抽出すれば、APIなくても何か出来そうな気はします]

しかし、基本的な考え方の単純さとは裏腹にこの方法は、色々と技術上本質的でない問題を起こすことがあります。

1つ目の問題は、Webサーバへの負荷です。
XMLやJSONと異なり、この方法でアプリがWebページを読み込む場合、Webサーバは人間が本来読むデータ全体を返します。
このとき、Webサーバの前提は「人が読むので一人あたりではそんなに高頻度では来ないだろう」という思い込みを持っていることがあります。
装飾データやイメージが埋め込まれていることもありますし、HTML自体が相対的にデータが大きくなりがちです。

しかしアプリの場合、このアクセスを1秒おきに行うといったことが人手を介さず、簡単に出来ます。
要は、機械が人間の代わりに「F5アタック」をアプリが行い続けるような実装をすることができます。
サーバ管理者からすると、行い方次第では大変迷惑な行為になります。
@<fn>{rest_is_exactly_same}

//footnote[rest_is_exactly_same][実際には、RESTなインターフェースでJSON等を取得するケースでも、似たような注意は成り立ちます。アクセスし過ぎはいわゆるDOSアタックです。DOS（Denial Of Service）アタックとは、大量のアクセスを行ってそのサービスを他の人が使えなくなってしまうWebサーバへの攻撃手段のことです。]

2つ目の問題は、運営者側がそもそもそんなこと期待していないということです。
XMLやJSONを提供している場合、少なくともアプリから読まれるという意図を持って、運用者がそのインターフェースを公開します。
その場合ですら、利用規約等によっては利用方法は制限されていることが多いです。@<fn>{google_is_doing_that}

//footnote[google_is_doing_that][GoogleのWeb上で無料公開しているAPI等も、よく見ると無料利用枠では"Courtesy Limit"という数値を公開していることがあります。「それ以上たくさんアクセスするのなら連絡してください」といった表現とセットです。]

HTMLのみで提供される、特に今回の例にでた「混雑状態」のような情報は、アプリで自動収集されることを特に望まれてないデータであるかもしれません。

仮に来場者全員が上の情報を元に計画を立てたとします。
すると「大変合理的な」ユーザの群れが「スッカスカ！」のアトラクションに突如大挙するなど、
本来来場者に期待される動きとは大きく異なる状態になるのは明らかです。

Web上にHTMLのみ公開するケースでは、あくまで「来場者や来場予定者がWebブラウザでちらちら見る」といった範囲に限定して、
利便性を向上させる意図で情報を公開している可能性があります。
そしてその場合、運営者は意図を超えてその情報を利用されるのは嫌がるでしょう。
Webサービスの利用規約に、それを禁止する文面がある可能性もあります。
@<fn>{sample_regulation}

//footnote[sample_regulation][例えば「本サイトからダウンロードした内容を別のコンピュータに配布してはいけません」といった文面が入っていたら、法律的に厳密なバトルを考えて弁護士を雇う前にまず、ウェブスクレイピングはやめることを検討するべきです]

1つ目も問題なのですが、2つ目の問題で、世間の常識と技術の常識が乖離していたことから逮捕騒動に至った事例もあります。
例えば「岡崎市中央図書館事件」もしくは「Librahack事件」では、サーバ負荷を低減させるためのスケジューラを実装し、技術的にはどう考えても高負荷とは言えない方法でアクセスした人が、Webサーバ側に実装のやっべー問題があるにもかかわらず一方的に逮捕されたという事案です。
本事件は本章筆者がきちんと解説出来る話ではないためこれ以上の説明は行いません。
ただ、そういう事件があったことは、アプリ開発者は気に留めておくとよいでしょう。
@<fn>{good_or_bad}

//footnote[good_or_bad][まさにこの記述を書く必要を感じる時点で、私個人としてもこの事件の萎縮効果は結構あるものと感じます。無視するわけにはいきませんしね。めんどうくさいのはWebだけじゃないね]

やや一般論として一歩引いて述べれば、Webサーバの運営は無料で自動的に行われるものではありません。
Webサーバの運営者が何をもってそのデータを公開し、何をもって事業を維持しているかを考える機会はあってもよいかもしれません。
@<fn>{allowance}

//footnote[allowance][明確に許可があれば、いいのかも。先日『百姓貴族』というコミックで次のようなエピソードを読みました。農家の人は作物を盗んだりしないそうです。そのかわり美味しそうなエダマメを他の農家が作っているときにはそこに行って、「美しいエダマメですね」「食べごろですね」「美味しそうですね」といかにも欲しそうな顔をしながら相手にコメントを述べ「持って行くかい？」という相手農家の譲歩を引き出すのでした。コミックのネタを文章で説明しても面白くもなんともありませんが、許諾を取れば、今回の問題の非技術的な側面の一部は実際解決される可能性があります。大手のテーマパーク運営会社には通じなそうですけど（『百姓貴族』p39）]


===[column] XMLやJSONって、コンピュータからすると効率悪くない？

ちゃぶ台ひっくり返しコラムへよおこそ。@<fn>{yookoso}

//footnote[yookoso][@<href>{http://www16.big.or.jp/~zun/}には長らく「よおこそ」と表示されています]

コンピュータ同士であれば、XMLやJSONのように「一応人間でも読める」フォーマットである必要性はありません。
コンピュータの基本に帰れば、バイナリを送る方法が効率はよいのです。
そのようにサービスを設計するケースも、当然あります。@<fn>{n_percent}

//footnote[n_percent][1億人が平均転送に10秒かかるデータ形式で1%速度を改善すると全世界で何分節約できるでしょう、みたいな話です。ラフすぎますが、だいたい一人の一生分くらい節約できます。世界全体で節約して一つ救える命があります。]

JSONについては批判・非難がそこそこあるにもかかわらず、利用例が多くなっている面白い例です。@<fn>{xml_was_more_popular}

//footnote[xml_was_more_popular][少し前後しますが、RESTfulについての教科書的な位置づけにある『RESTful Webサービス』のp5に「プログラマブルWebはHTTPとXMLに基づいている。一部でHTML、JSON（JavaScript Object Notation）、プレーンテキスト、またはバイナリデータを扱うが、ほとんどの部分では、XMLを使用する。」とあり、読んでいてむしろ驚きました。邦訳は2007年です。当時はRESTという世界でJSONがあまり認められていなかったということなのでしょうか。]

Erlangという近年人気が上がっているプログラミング言語の著名人の一人Loïc Hoguinが
ML上で取り上げたJSONの3つの問題を転載します@<href>{http://erlang.org/pipermail/erlang-questions/2014-March/078228.html}

  *  It's text-based, meaning it's incredibly slow to parse.
  ** (引用者訳: バイナリではなくテキストベース。なのでパースがとても遅い)
  *  It has to be valid UTF-8, meaning it's incredibly slow to validate.
  ** (引用者訳: UTF-8必須、検証がとても遅い)
  *  Its numbers representation is double-precision floating-point, meaning it's incredibly imprecise and limited.
  ** (引用者訳: 数値表現が倍精度浮動小数点のみで、不正確で限界がある)@<fn>{innaccurate}

//footnote[innaccurate][調べてみた限り、実はこの説明自体は仕様の側面だけで読み取ると、不正確のようです。JSONのRFC 7159自体にはこのようなことは書かれていません。ただし、JSONを複数の異なる環境で共有する際にはdouble(64bitsの倍精度浮動小数点)を必要とし、さらに実装によっては数値データを整数と区別せず一律doubleのみで実装してしまった結果、あろうことか整数の範囲が52bits（doubleの仮数部）で表現される範囲に限定された、という実務上の非常に微妙な制約が実際のJSONにあるのは事実です。そしてそれがJSONを利用する実装の大多数であるため、実際にここに書かれている批判が妥当性を持つのでした。私の説明も不正確かもしれませんので、何度も書きますが、疑問があったらとりあえずRFCから読みましょう]

この「最適じゃないよね」という類の話は、実際、さらに発展させることができます。
HTTP使わずに独自プロトコルのほうが効率的な通信をできるはずです。
TCP/IPでは再送制御の分だけプロトコルが重くなってますので、UDPや独自の方法で適宜処理したほうが効率がよいのではないか、等々。
@<fn>{hpc_uses_special_cable}

//footnote[hpc_uses_special_cable][このような「オレオレ最適化」の夢想の中で、物理層とその周辺だけはこのようなアイディアがリアルに実現される領域かなぁとふと思いました。無線LAN遅いから優先にするわ、っていう発想は有効なもので]

通信プロトコルについてのこのたぐいの批判は、理屈上はみな正しいとも言えます。
しかし通常は、あまり現実的とは言えません。
@<fn>{google_may}

//footnote[google_may][スイッチ業者やGoogleのような大手であればこういう発想が生きる領域がありそうです。実際SPDYのようなプロトコルを考えるエンジニアが世界にいるわけですし]

ここで詳細な説明は省略しますが@<fn>{author_doesnt_know}、例えば以下のような問題が各段階ではびこっています。

 * TCP/IP以外のパケットを遮断するネットワークがしばしば存在します
 * TCP/IPの80番、443番ポートなど、HTTPのポート以外を遮断するファイアウォールが良くあります
 * HTTP以外の怪しいパケット遮断するという設定でファイアウォールを運用できたりします@<fn>{deep_packet_inspection}
 * 共有される適度な転送上の仕様を共有するのが面倒くさいケースがあります

//footnote[author_doesnt_know][というか、筆者が説明できません]
//footnote[deep_packet_inspection][「ディープ・パケット・インスペクション」などの用語で調べてみてください]

個々のコンポーネントが最適でない、という問題はしばしば起こります。
そして、それを納得した上で、他のサーバが採用しているからそのままその方式を使ったりもします。

HTTP上のフォーマットについて言えば「皆が使っているので使っている」というケースがしばしばあります。
実際一般的なAndoridアプリ開発者であれば、おそらくこのケースでWebサーバ上からデータを取ってくることが多いでしょう。
別の理由は「自分が知っている馴染みのあるフォーマットだから」です。
JSONはJavaScriptとの相互運用において優れたフォーマットであるため、HTML5のコンテクストでは圧倒的です。

皆が使っているからそれが唯一最高の方法と言えるわけではないのはもちろんです。

上記Erlang界のカウボーイは同じメッセージでケースバイケースだけどmsgpack（MessagePack）を使うことが多い、とも書いています。
このmsgpackは、おそらく本コラムの疑問を持つような優秀な読者の疑問を一つ解決してくれるかもしれません。
これはバイナリ型のデータフォーマットで、当然JSON本来よりは一般に効率がよいと考えられます。
@<fn>{other_binary_protocols}

//footnote[other_binary_protocols][コンピュータ間の転送に使われるバイナリ型のデータフォーマットにはその他にもProtocol Buffersといったものもあります。]

TCP/IP、HTTP、JSON（XML）の組み合わせが普通使われますし、十分いろいろなことができます。
一方、自分のサービスを他者から区別する要素となりえるのであれば、プロトコルの再設計は選択肢の一つ「かも」しれません。

ただしそういう場合、少なくともWebに潜む典型的な課題を理解してからのほうが、典型的な落とし穴にハマる確率は減るでしょう。
このようなトピックは残念ながら本書の範囲外です。
@<fn>{author_doesnt_know_more}
@<fn>{erlang_is_great}

//footnote[author_doesnt_know_more][虚飾を廃して言い直すと、少なくとも本章担当者が説明できるレベルをかるーく超えてます]
//footnote[erlang_is_great][むしろ上のMLでの発言は「お前Erlang使ってんだからそんくらい考えて欲しいよ」という叫びなのかも。Erlang素敵です。Androidで動くかは定かではありませんが]

===[/column]


== Webに関するその他のトピック

本節では他の部分で説明出来ていない内容を書き並べていきます。

=== 認証・認可

かつてはあまり意識されませんでしたが、現在のWebでは「認証」（Authentication）と「認可」（Authorization）は分けて考えるのが一般的です。
AndroidアプリでWebサービスを利用する上でもしばしば目にするでしょう。

二つの言葉の意味するものをひとことで言えば以下のとおりです。

 * 認証: 本人確認
 * 認可: アクセス許可

役所で書面で情報を受け取ることを考えてみます。

申請書類を書いて、免許証と申請書類を提出し、役所が大丈夫だと思えば、役所が持っている情報を提供してくれます。

免許証を見せることは自分が本人であることの確認です。
「自分である」ことを示す方法は複数あります。
免許証でなく、パスポートでも通常問題ありません。
おそらく、DVDレンタル屋のポイントカードですと、訳書ではこの役は果たしません。

見せたからと言って、申請する書類の許可が常に得られるとは限りません。
例えば自分自身の戸籍に関する情報なら、おそらく取得できます。
しかし役所で管理している人の情報はその限りではありませんし、例えば公開されていない役所内の職員の生年月日の情報をその方法で教えてくれるとは思えません。
あなたが誰であるかを確認する行為（「認証」）と、その人に何かを行う権限を与える許可をする行為（「認可」）は別のことです。

本章前半のスーパーなるえつの例を見なおしてみます。
客が梅干しの在庫を問い合わせる際、自分が誰であるかを名乗っていないのに、
梅干しの在庫情報を得ることが出来ました。
うめぼしの在庫情報はスーパーにとって秘密の情報でもなんでもなく、
相手がただの客であっても提供しても問題ないことが明らかです。

ここで「おたくの金庫の中にいくらありますか」という質問をした場合、話は変わります。
誰であるかわからない客に店の秘密の情報を教えることは通常ありません。

この例では客は「名前も名乗らぬ客です」と言っています。
言い換えると、客は「自分は認証されてない」と宣言しています。

ここで例えば「ああ、私だ」とまず客らしき人が言って、
店員がその声紋から客らしい人を店長と「認証」すると、
金庫の中の情報を教えてもよいという判断になるかもしれません。
「認証」の上で「認可」が発生します。

Webでも「認証」と「認可」は自然に分離されています。
ソーシャルWebサービスでAさんがログインして、
そのあと全くの他人であるBさんの秘密の写真を見ようとした例を考えてみます。
認証はされています。AさんであることをそのWebサービスは知っているはずです。
しかし、Bさんの秘密の写真を見せてくれるわけではありません。
「認証」はされているが「認可」はされていないことになります。

一方、CさんというBさんの知り合いがいたとします。
そして、AさんがCさんにはその秘密の写真を見せてもよいと、そのWebサービスに伝えていたと仮定します。
@<fn>{trip_photos}

このとき、Cさんとして「認証」されたユーザは、そのBさんの秘密の写真を見ることを「認可」されます。

//footnote[trip_photos][旅行に行った友人同士で写真を「ショア」する、といった形式で実際に発生します。]

Webにおける認証と認可の実装は、あまり統一的とは言いがたい状態です。
とりあえず、認証の実装について考えてみましょう。

古くからあるHTTPでは認証の仕組みは以前からあります。
BASIC認証とDIGEST認証が代表例です。
@<fn>{rfc_for_basic_and_digest}

//footnote[rfc_for_basic_and_digest][RFC 2617 "HTTP Authentication: Basic and Digest Access Authentication"]

しかし一般のWebサービスでこれらを標準のログイン方法として使うサービスはあまりありません。
@<fn>{reason_of_unpopular_basic}
もっぱら、HTMLのフォームやHTTPのPOSTメソッド等を使った「フォーム認証」が一般的です。
本章のPython + Djangoの例でも「フォーム認証」を例に取った認証の例を示します。

//footnote[reason_of_unpopular_basic][使われない理由として、ログアウト方法がブラウザを閉じる以外にない、UIがHTMLのWebページとシームレスに繋がっていないため詐称に弱い、といろいろな要因を聞いたことがあります。ただ全く使われないかというとそうでもありません。ApacheのようなWebサーバはそれ自体でBASIC認証を取り扱う仕組みを持つため、手軽に「アクセス制限のあるデータ置き場」を作る際には筆者もよく使います。また、HTMLのようなUIがないWebアプリケーションの一部でBASIC認証を使う例を見たことがあります。マイナーですがSAMLというSSO（Single Sign On）の仕組みで、さらにECP（Enhanced Client Proxy）という拡張を使う際にBasic authが使われており「ずいぶん遠方の地でも頑張ってるなぁ」とむやみに感心した記憶があります。いみわからないね]

フォーム認証をするWebサービスの場合、Androidアプリにそのサービスをそのまま組み込むのはしばしば面倒です。
Androidアプリへアクセスを「認可」するOAuthのような技術を使うケースでも若干特殊な画面遷移を踏むことになります。
サービスによっては独立にトークンとシークレットの組を発行しておく必要もあります。
@<fn>{authenticator_is_good}

//footnote[authenticator_is_good][Android上でAuthenticatorを実装してくれているとそのWebサービスのアプリ開発者的には認証認可が楽になったりすることがありますが、これもある意味ではAndroid独自の世界観です。OpenIDやOAuthというキーワードも今後重要になっていくはずですが、本章では省略します。]

=== httpsと証明書

Webについて、特にHTTPというデータ転送プロトコルをこれまで見てきました。

TCP/IPとセットにして使っている際、インターネット上にはHTTPのパケットがそのまま送信され、
インターネット上でそのパケットを中継する全てのコンピュータが中身を覗き見ることが出来ます。
ユーザ名や、あろうことかパスワードも含めてです。

ニュースや天気予報のWebサイトならこれでも大丈夫かもしれませんが、
Webメールサービスや銀行のWebサイトではこれは大変困ります。

そこで、HTTPのやりとりをサーバとクライアント間で行う際、最初に
「暗号化しましょ★」「そうしましょ☆」
と約束するHTTP Over SSL/TLSというプロトコルが発達しました。
ここで暗号化というのは要は「途中にいるひとが盗み見ても通信の意味がわからない」といった意味です。

@<href>{https://example.com/}といった形で冒頭にhttpsというscheme要素が入った
URIでは、このTLS（Transport Layer Security）という通信方式をTCP/IPとHTTPの間に挟んで使います。
@<fn>{ssl_is_old_tls}

//footnote[ssl_is_old_tls][SSL（Secure Socket Layer）という表現で言及されることのほうが多いかもしれません。大雑把に言えばネットスケープ社が独自に作ったSSLの特にSSL 3.0をもとにIETFがRFC 2246として仕様策定したのがTLSで、以降TLS 1.1（RFC 4346）、TLS 1.2（RFC 5246）と、新しいバージョンは一様にTLSと呼ばれています。実用上は実際しばしば古いSSL 3.0等を使っていることも多いようですが、ここでは説明は避けておきます。]

HTTPS（TLS）は、HTTPにかけているものをいくつも補完してくれるとてもありがたい存在です。
ひとつはすでに述べた「暗号化」です。
URIではhttpsとなり、スキームが異なります。
Webサーバが提供するTCP/IPのポート番号も80番ではなく443番になります。

HTTPに欠けている「欲しい機能」はまだあります。
例えば、相手（特にWebサーバ）が本当にクライアントの期待した相手であるかを証明（認証）する手段はHTTPにはありません。
確かにHTML上に「スーパーなるえつです」と書くことは出来ますが、誰かが保証してくれるわけではありません。
この問題はスーパーのうめぼしを確認するケースよりも、銀行の送金をするときに大問題になります。

HTTPSではこのとき、通信に使う暗号化の「鍵」とセットで、「サーバ証明書」をWebサーバからクライアントに最初に送ってもらうことで、この問題を軽減します。
「自分は〜〜と他の人に認めてもらってますよ」というお墨付きを、サーバは前もって誰か別の組織からもらって、それをクライアントに提供することでクライアントに「あー、あいつらがお墨付きを与えてるのか、じゃあ、間違いなくこのWebサーバは自分が接続したいサーバだ」と判断します。
@<fn>{client_certificate}

//footnote[client_certificate][サーバの証明書だけでなく、実はクライアントの証明書というのもあります。例えば大学が学生証とセットでそういうデータを配布PCに埋め込んでおき、配布PCでだけ見られる学内のWebサービスを提供する、という用途として使えることがあります。これまでのBASIC認証やDIGEST認証やフォーム認証とも異なる認証方法です。]

HTTPにもうひとつ欠けているものは「本当にそのデータ、正しい？」です。
スーパーなるえつがWebサーバを提供して、いつでも最新の大山の梅干しの在庫を返してくれると謳っていたとします。
でもHTTPの性質上、インターネット上の途中のサーバは中身を見放題で、実は書き換えすらできてしまいます。

「在庫あるよ」となるえつのWebサーバが返す際、その通信を中継する悪意のあるサーバが
「在庫ないよ」と2文字書き換えることが可能になっています。

これを「完全性保護」などと呼んだりします。
HTTPSではこの問題も実は解決することができます。

以上、大きく分けると「暗号化」「認証」「完全性保護」がHTTPに欠けていて、
TLSを組み合わせたHTTPSがWebに提供するとても素晴らしい仕組みなのでした。
ついでにTLSはまたしてもRFCで規定がありますので、いろいろなWebブラウザやWebサーバが
仕様を元に実装することが出来ます。

ここまで、理屈上はいいんですよね。

HTTPにしてもHTTPSにしても、大事なデータが流れてる時には攻撃者はそれを欲しがります。
HTTPSでちょっと守ったとしても、仮にどこかに「情報を盗めるチャンス」があれば、
攻撃者によって機密情報を取られたり、送金額を改ざんされてしまったりするわけです。

例えば「暗号化」。「暗号化」の詳細は本章では一切説明しませんが、
意味のある暗号化通信には、必ず「暗号を解く鍵」が存在します。
それは通常、信頼したい受信者が持ちます。
これが攻撃者に漏れてしまうと、暗号化は無意味です。
そういった鍵が漏れていない場合でも、仮に鍵の「強度」が弱ければ、暗号を読み取られてしまいます。
ピッキングでこじ開けられるドアみたいなものです。
@<fn>{cryptanalysis}

//footnote[cryptanalysis][暗号自体はインターネットの歴史と関係なく存在し、戦争の勝敗を決する要素にすらなります。サイモン・シン『暗号解読』などを参照してください。]

「証明書」についてもやはりしばしば問題になります。
この方式をしっかり成立させる上ではかならず、クライアントとサーバーの他にもう一つ信頼のおける「認証局」が必要ですが、この認証局自体が攻撃者によって攻撃され、偽物の証明書を発行してしまうことがあります。
@<fn>{diginotar}

//footnote[diginotar][2011年にオランダのDigiNotarという認証局が本当にこの問題をやって、GoogleやTwitterといった大手Webサービスの不正な証明書を発行してしまったそうです。その後、潰れました。@<href>{http://en.wikipedia.org/wiki/DigiNotar}]

まだまだ山のようにあります。
BEAST攻撃にHeartBleed脆弱性にと、次々にHTTPSを脅かす問題が報告され、
その都度実装を修正したり、仕様を修正して次につなげたり、仕様の一部を無視するようにしたりしています。
@<fn>{dns}

//footnote[dns][HTTPS「が」問題というわけではないので勘違いしないように。インターネット全体が多くの人によって使われるようになり、お金や政治が係るようになった結果、Webにしろそれより広いインターネットにしろ、どこかしらで攻撃が成功すれば利益が生まれる人々や集団が普通に現れてきた、という解釈を筆者はします。ただその性質上、HTTPSは特に攻撃対象として「おいしい」のかもしれません。Web以外にもいろいろ大問題になっている話は他にもあります。UDPとDNSとか。残念ながら筆者が解説レベルにありません。]

Androidアプリ利用者という視点で考えた場合に一つ重要なのは、まず古いバージョンのAndroid OSをなるべく使わないことです。
一部のHTTPS（TLS）に関わる脆弱性はOSに付随するもので、Androidアプリレベルでの修正が困難なこともあります。
利便性などがあまり変わらない、最新の端末高い、といった面は実際あるのですが、比較的わかりやすい情報漏えいの入り口となってしまうことがあります。

Androidアプリ開発者の視点から見ると、悩ましいところです。
本章とは独立した章を別の人に書いてもらう希望を抱いて、次。

===[column] httpsに対するtelnet風の接続

TCP/IP上のナマ接続を行うtelnetコマンドでは、HTTPSのWebサーバと対話的にやりとりをするのはほぼ不可能です。
TLSの暗号化を伴うやりとりを手動で行うことになるためです。

TLSに相当する層を代わりに行ってくれるコマンドとしてOpenSSLの提供するコマンドラインツール"openssl"
が候補の一つとして挙がります。
具体的には以下のようなコマンドで、TLSの暗号化部分を代わりにopenssl部分がやってくれる、telnetライクなやりとりが行えます。

//emlist[opensslでHTTPS接続を試す]{
$ openssl s_client -connect mowa-net.jp:443
//}

ただし、TLSのやりとりに関する情報も出力されるため、雰囲気はだいぶ異なります。

===[/column]

=== JavaScriptとHTML5的Webアプリケーション

Webが生まれた当初、HTMLは学術論文のような、基本的に読むためのドキュメントを表示するものでした。
当時独特だったのはそこに「ハイパーリンク」という相互参照で相手のドキュメントに直接移動する仕組みで、
そこに画像を埋め込むといった機能があったとはいえ、Webページは、ユーザの操作で変化するものではありませんでした。
@<fn>{why_I_repeat}

//footnote[why_I_repeat][「当初のWeb」を何度も説明してます。一応意図を説明しておくと、ある種の遺産がそこに存在する前提でWebが非常に上手く進化しつづけてきたことを再確認して欲しいからです。理想論を語ればインターネットはこのような形にはならないと言う方もいます。ただ、進化過程の制約を上手く回避することで誰もが使える現在のWebになっているということを忘れると、自明に失敗する「新しいこと」を思いつきがちです。]

現在では状況は異なっています。
クリックすれば画面上のボールがぽよーんとなったり、音楽が再生されたり、ゲームを出来たりします。

現在これを達成するためには、大きく分けると3通りの方法があるように思えます。
1つ目はFlashのような「プラグイン」です。
2つ目はAndroidアプリのように「独立したアプリを作る」方法です。
3つ目はWebサーバからHTMLとともにJavaScriptといったプログラミング言語で書かれたアプリケーションそのものを動的にダウンロードし、Webブラウザ内でプラグインの助けなしにアプリケーションを動かすモデルです。
かつては「Web 2.0」、執筆時にはHTMLの新仕様であるHTML5にあやかって「HTML5アプリ」などと言われたりします。
@<fn>{approximation}

//footnote[approximation][この3種類を厳密に分離するのは実際には不可能ですが、おおまかな区切りとしては便利です。]

本章全体にわたり、Webの2つ目の形態に役立つ部分を中心に説明しているつもりですが、
現在では3つ目の形態でアプリを書くことも増えています。

HTML5的なアプリの肝は既存のWebとの互換性と、その中で進化してきたWebブラウザ・Webサーバの追加仕様・実装にあると考えられます。

これまで見た古いWebの技術では、残念ながらHTML5的なアプリというのはそもそも不可能でした。
ダウンロードされたコンテンツをユーザの操作に応じて一部アップデートしたり、
サーバから通知をプッシュしたりすることが出来なかったためです。

そこに、AjaxやComet（後のWebSocket）といった、Webサーバとのデータ転送をやりやすくなる仕組みが発達し、一方OS側のネイティブに近い機能を楽に利用する例としてWebGLやNaCl、WebRTCやWeb MIDI APIといったブラウザ互換を目指す仕様が続々と提案・追加されてきました。
JavaScriptというWebブラウザ上で動くプログラミング言語の事実上の標準もあいまって、一大世界を作り上げています。
@<fn>{my_own}

なお、最近ではJavaScript代替としてDartというGoogle起源のプログラミング言語もあります。
ECMA-408として標準化され、今後、他のブラウザでの実装が進む可能性が生まれてきました。
JavaScriptへコンパイルされる類のプログラミング言語もあり、一層多様性の豊かな世界です。
本章でのこれ以上の軽率な説明は是が非でも控えたいところです！

//footnote[my_own][あまり詳しい領域ではないので重要度ではなく趣味で選びます。紹介した例の中には標準化に至っていないものまであります。本章筆者の浅い経験の範囲でも、NaClのおかげで実際C言語レベルでしか提供されないライブラリをWebブラウザ上で使えて助かったことがあったりします。Web MIDI APIの関係者が大学時代の先輩だったり。これってステマと呼ばれそう]

本章でAndroidのアプリとHTML5の比較等は避けておきます。
ここで言及しておきたいのは「古くからの同じプロトコルから、多様な世界が構築されている」という点までです。
この世界での最下層であるHTTPやURIという概念が、だいぶ異なる用途に対しても驚くほどうまく働く点を、
本章では強調しておきます。

と、説明を放棄しまして、次へ。

== そして、Webサーバ

本節ではWebサーバからみたWebを考えてみます。

また、Webサーバ上のWebアプリケーションを作成する例を通して、
Androidアプリが会話する「向こう側」がどう作られるかの一例を示します。

=== 基本はHTTPのレスポンスを返すこと

Webサーバから見るとリクエストは「来る」ものです。

//image[server-1][Webサーバはレスポンスをうやうやしく返す]{
//}

あるWebブラウザが「index.htmlをクレ」と言ったとします。
これに対してWebサーバは「これだよ」「ないよ」「別のURIに移動したよ」と、
適切なHTTPレスポンスを返します。
具体的には、HTTPでは200（Found）、404（Not Found）、301（Moved Permanently）といった
レスポンスの種類に対して番号が対応するところまで、すでに説明しました。

この番号と、必要ならリソースの中身も返すこと、これがWebサーバの基本的な役割です。

=== レスポンスの仕方はある程度Webサーバに任されている

Webサーバにとって、クライアントの目的は自分の持つ「リソース」です。
URIで指定したリソースについての状態と中身が返ってくれば、クライアントは満足です。
たとえ404（Not Found）でも、クライアントからすれば「ない」ことが重要な情報なこともあります。

すでにURIの説明であった通り、Web上のリソースはURIによって一意に識別されます。
よって、Webサーバはそのリソースを階層構造・ツリー上にマッピングする必要があります。
しかし、HTTPでその方法が規定されているわけではありません。

サーバのトップページ（@<href>{http://example.com/}）がクライアントから要求された状況を考えます。
「index.html」というファイルがWebサーバのどこかにあった場合、それを返して構いません。

//image[server-2][これがindex.htmlでゲソ]{
//}

一方、Webサーバが代わりにそのときに内容を作って、HTTPレスポンスで返しても構わないわけです。
あるURIで一意に識別されるリソースの提供方法はHTTPの規定にはありません。
例えば"Hello World"とだけテキスト形式でHTTPレスポンスを返すWebサーバがあっても、
WebサーバもWebブラウザもそれで「困ったり」はしません。

//image[server-3][動的にindex.htmlを作成する]{
//}

実際、大手ニュースサイトのトップページはいつもめまぐるしく入れ替わっています。
検索結果もWebサーバ側がいつも変えています。
現在では、Webサーバが情報を加工して返答するのが非常に一般的です。

Webサーバを作る最も単純明快な方法は、HTTPレスポンスの「超・絶・簡・単バージョン」を返すプログラムを書いてしまうことです。
"Hello World" WebサーバでもWebにあってHTTPをしゃべる限りはWebサーバです。

ネットワークの章でTCP/IPのソケットプログラミング等を学んでいれば、
このソケット経由で"HTTP/1.1 200 OK"から始まる一連の文字列を返してあげれば、Webサーバの出来上がりです。

//emlist[以下の同じ返答を返すHTTPサーバならもう作れるはずです]{
HTTP/1.1 200 OK
Content-Type: text/plain

Hello world
//}

でもそのレスポンスではクライアントにとって役にたちません。
いつも200と同じ文字列を返すのがわかっているなら、そのサーバへアクセスする必要すらありません。

一般的には、Webサーバはクライントに価値ある何かを「覚えて」いて、
それをユーザに適切に提供することではじめて意味を持ちます。
POSTメソッド等によって、クライアントからリソースの変更要求があることも一般的です。

HTTPリクエストに応じて適切な応答を返そうとなると、実装が一気に難しくなります。
すでに説明したWebに関わる面倒な詳細を本当に全て自分で書くのは大変ですし、
セキュリティやクライアント側の問題を考慮した上で、
ユーザにとって満足のいく応答を返す必要があります。
@<fn>{was_easy}

//footnote[was_easy][「そんなん簡単だろー」と誰かが実装した結果、脆弱性が混じって世界に迷惑を撒き散らす「迷惑サーバ」が生まれる、ということが繰り返されてきました。一般論です。]

それでも、そのWebサーバへアクセスするクライアントが少なければ、なんとかなります。
あるいは、Webサーバが覚えておくリソースが少量で固定されているのであれば、問題はそこまで難しくありません。

大量のアクセスがあるWebサーバは、その「大量のアクセス」の性質次第でさらに多くの課題を持ちます。
もちろん、WebにはHTTP（とURI）という皆が守るべき仕様があることも忘れてはいけません。
これに違反しすぎるようだと、いくら大量のアクセスを想定したWebサーバでも価値が下がります。

//image[server-4][ラフ絵でも連載が成り立つ漫画家はすごい]{
//}

リソースの重要度に応じてセキュリティやその他の課題も、Webサーバの開発者・運用者は併せて考えていく必要があります。


=== Webサーバ（アプリケーション）を「効率良く」実装する

Webはすでに大変複雑な技術と化しています。
いくら仕様があるとはいえ、自力で全てを実装するのは現実的ではありません。
前もってWebにおいて発生する典型的な問題を解決する仕組みを備えた「フレームワーク」が欲しくなります。
@<fn>{about_framework}

//footnote[about_framework][Frameworkは英語で「骨組み、枠組み、骨格」という意味です。肉付けする前にしっかりした土台を提供してくれるもの、というイメージでコンピュータ関連でよく使われます。]

Webアプリケーションフレームワークは、そういった問題の多くを解決する方法を提供してくれます。
HTTPリクエストやレスポンスをそのプログラミング言語の「クラス」や「オブジェクト」のような
内部構造にうまくマッピングし、直接HTTPの細かい規約に合うように調整までしてくれます。

telnetコマンドとcurlコマンドがすでに登場しているので、この2つを比喩に説明してみましょう。

かつてのWebプログラミングでは、telnetコマンドのように生のやりとりを直接記述することがありました。
しかし、このやりとりはプログラミングのミスをあまりにも簡単に発生させます。

curlのように、ある程度HTTPのやりとりを肩代わりしてくれるライブラリのようなものがあれば、
問題は軽減されるはずです。
それがWebアプリケーションフレームワークです。

よいフレームワークは単純にHTTPの肩代わりをしてくれるだけではありません。
既存のWebアプリで頻繁に発生するセキュリティ上の脆弱性の問題を予め回避したり、
回避を容易にしたりする仕組みが備わっていることが多いです。
後述するCSRF（Cross Site Request Forgery）脆弱性にはそういった問題の典型的な解決策があります。
多くのフレームワークは、そういった典型的な「落とし穴」に対する解決策を提供してくれるのです。
@<fn>{someone_screams}

//footnote[someone_screams][当たり前のことですが、皆が協力して作らなければWeb上のフレームワークは出来ません。それはWeb上のどの要素でも同じことです。]


=== Python + Djangoでサーバを作る。

と、実際のところ説明してもよくわからないので、本章ではWebアプリケーションフレームワークを使った実例を紹介することにしました。

ここでは、プログラミング言語Pythonとその上で動作するWebフレームワークDjangoという組み合わせにより
Webサーバ上のアプリケーションを実際に作ることを試みます。
@<fn>{why_django}

Pythonはプログラミング言語の一つです。
そしてDjangoはPythonで利用できる有名なWebアプリケーションフレームワークの一つです。
サーバ環境はLinuxのUbuntu系OSを使います。

//footnote[why_django][なぜこの組み合わせかというと、単純に本章担当者が使っているためです。]

==== Pythonについて少し

本書はAndroidアプリ開発者にPythonを紹介するものではないため、言語やフレームワークの詳細な説明は省略していきます。

JavaとAndroidアプリを作る場合と比較して、目につく違いについてざっと説明すると以下のとおりです。

 * #以降がコメントとして扱われます。
 * 変数宣言時に型を明示しません（Pythonはいわゆる「動的型付け言語」と呼ばれます）
 * 明示的にコンパイルを行う必要はありません（Pythonはいわゆる「スクリプト言語」と呼ばれます）
 * ブロックはファイル内のインデントによって表現します。
 * 文字列は""と''の両方を使えます。「文字一文字」という型がありません。

==== プロジェクトを作る

Linux環境の/optディレクトリに/opt/helloworldというプロジェクトを作ることにします。

//emlist[helloworldプロジェクトを作る]{
$ python --version
Python 2.7.3
$ django-admin.py --version
1.6.5
$ cd /opt
$ django-admin.py startproject helloworld
$ cd helloworld/
$ ls -R
.:
helloworld  manage.py

./helloworld:
__init__.py  settings.py  urls.py  wsgi.py
//}

django-admin.py はDjangoがもともと提供する管理者用プログラムで、ここではhelloworldというプロジェクトを作っています。
".py"で終わるファイルがPythonスクリプトのファイルです。
ここではhelloworldモジュールがすでに作成されており、プロジェクトの設定を司るsettings.pyを始めとしていくつかの
標準的なファイルが自動的に作られています。


//emlist[helloworldプロジェクトを実行する]{
$ python manage.py runserver
Validating models...

0 errors found
July 08, 2014 - 07:22:45
Django version 1.6.5, using settings 'helloworld.settings'
Starting development server at http://127.0.0.1:8000/
Quit the server with CONTROL-C.
//}

この時点でDjangoのプロジェクトは試験用のサーバを立ちあげてしまうことができます。
"python manage.py"はこのプロジェクトを管理するための各種サブコマンドを実行するためのコマンドです。

ここでは"runserver"サブコマンドでDjango組み込みのWebサーバを立ち上げています。
この状態でhttp://127.0.0.1:8000/へブラウザからアクセスすると@<img>{django-01}のようになります。

//image[django-01][作りたてのDjangoサーバ]{
//}

@<img>{django-01}はDjango自体が表示しているページです。ここから順番にWebアプリを作っていきます。

==== DBを用意する

Djangoでは複数のSQLエンジンをDBバックエンドとして利用することができます。

今回利用している環境の場合、作られたプロジェクトではすでに
SQLiteというSQLエンジンを使う設定ができていました。
その設定を元に実際にDBを準備してもらうことにします。

//emlist[sqliteを使ってDBを準備する]{
$ python manage.py syncdb
Creating tables ...
Creating table django_admin_log
Creating table auth_permission
Creating table auth_group_permissions
Creating table auth_group
Creating table auth_user_groups
Creating table auth_user_user_permissions
Creating table auth_user
Creating table django_content_type
Creating table django_session

You just installed Django's auth system,
which means you don't have any superusers defined.
Would you like to create one now? (yes/no): no
Installing custom SQL ...
Installing indexes ...
Installed 0 object(s) from 0 fixture(s)

$ ls
db.sqlite3  helloworld	manage.py
//}

"db.sqlite3"というファイルがプロジェクトのディレクトリ内に作られています。

SQLiteはファイルにデータを保存する軽量のSQL実装で、
独立したデーモンやサーバが要らず軽量でもあるため、
特に実験時のWebサーバ開発や組み込み開発で良く使われます。
@<fn>{android_uses_content_provider}

//footnote[android_uses_content_provider][AndroidでもContentProviderの背後でSQLiteが動いていることはきっとご存知でしょう]

この時点では、サーバで保存するデータについてまだ何も記述してません。
しかし、DjangoがDjango自身を管理する情報はすでにDBに書き込まれています。
SQL文を発行してその中身を見てみましょう。

dbshellサブコマンドは、そのプロジェクトで利用されているDBエンジンに合わせてDBとのインタラクティブ環境を起動します。

//emlist[DBの中身]{
$ python manage.py dbshell

sqlite> .tables
auth_group                  auth_user_user_permissions
auth_group_permissions      django_admin_log          
auth_permission             django_content_type       
auth_user                   django_session            
auth_user_groups

sqlite> SELECT * FROM auth_permission;
1|Can add log entry|1|add_logentry
2|Can change log entry|1|change_logentry
3|Can delete log entry|1|delete_logentry
4|Can add permission|2|add_permission
5|Can change permission|2|change_permission
6|Can delete permission|2|delete_permission
7|Can add group|3|add_group
8|Can change group|3|change_group
9|Can delete group|3|delete_group
10|Can add user|4|add_user
11|Can change user|4|change_user
12|Can delete user|4|delete_user
13|Can add content type|5|add_contenttype
14|Can change content type|5|change_contenttype
15|Can delete content type|5|delete_contenttype
16|Can add session|6|add_session
17|Can change session|6|change_session
18|Can delete session|6|delete_session
//}

この例ではいくつかのサーバ側パーミッションがすでに準備されていることが分かります。

==== Hello Worldサーバ

さて最初に"Hello World"とだけ返すWebサーバを作ってみます。

helloworldプロジェクトを作成した時点でhelloworld/ディレクトリに以下のようなファイルが出来ています。
@<fn>{django_may_do_differently}

//footnote[django_may_do_differently][Djangoのバージョンによってもファイルの内容は少しずつ違ってきますが、概略は同じです。]

//emlist[helloworld/urls.py]{
from django.conf.urls import patterns, include, url

from django.contrib import admin
admin.autodiscover()

urlpatterns = patterns('',
    # Examples:
    # url(r'^$', 'helloworld.views.home', name='home'),
    # url(r'^blog/', include('blog.urls')),

    url(r'^admin/', include(admin.site.urls)),
)
//}

ここでは、URIのpath部分を正規表現でチェックしていき、
マッチするものがあればそれに対応する関数にルーティングするという処理をしています。
もともと、そのプロジェクトの管理者用のページとして"admin/"についての実装が入っています。
@<fn>{string_for_regex}

//footnote[string_for_regex][そもそも文字列がシングルクォートで囲われていて気持ち悪いのに、rが先頭に付いていてさらに気持ちが悪いかもしれません。例えば"\\\\"とバックスラッシュをバックスラッシュでエスケープするという面倒を避けるために、Pythonではしばしばrを文字列の前に前置してバックスラッシュを特別扱いしない挙動を強制することがあります。なお、rが接頭辞についた文字列自体が自動的に正規表現オブジェクトに変換されるわけではありません。]

ここでWebサーバのトップページに"Hello World"を表示させてみることにします。

//emlist[helloworld/urls.py を改変する]{
from django.conf.urls import patterns, include, url

from django.contrib import admin
admin.autodiscover()

urlpatterns = patterns('',
    url(r'^$', 'helloworld.views.home', name='home'),
    url(r'^admin/', include(admin.site.urls)),
)
//}

一行、意味のある変更を加えています。

//emlist[意味のある部分]{
    url(r'^$', 'helloworld.views.home', name='home'),
//}

これは
 * HTTPリクエストのURIでpathが何も指定されていないときに@<fn>{uri_path}
 * helloworldモジュール内のviews.pyというファイルにあるhome()関数を実行しろ
 * このルール自体の名前をhomeとする

という意味になります。
@<fn>{regex}

//footnote[uri_path][URIの各部品の名前を覚えてますか。ここではpathだけ記述し、他の部分はDjangoやDjangoプロジェクトを使うWebサーバが丁寧に処理してくれます]

//footnote[regex][正規表現を学んでいない可能性もあると思うので、正規表現部分に当たる^$を説明しましょう。^は先頭です。$は末尾です。「先頭と末尾がくっついている」とは、つまり「空の文字列」です。この正規表現自体は文字が入ることを一つたりとも許しませんが、Djangoの機能によって、URIのpathに入る"/"に関連した扱いにゆらぎが許されています。]

最初のプロジェクトではviews.pyというファイルがないので、ここで作ります。
@<fn>{django_does_not_recommend_this}

//footnote[django_does_not_recommend_this][この方法を取ると、設定とコードが混じってしまい「後々」問題になるかもしれません。Django公式のチュートリアルでは、ここで"app"と呼ばれる、プロジェクトと独立した再利用可能なモジュールを作り、そちらにコードを配置しています。今回はそのあたりの処理は省略してしまっています。]

//emlist[views.py]{
from django.http import HttpResponse

def home(request):
    return HttpResponse('Hello World\n', content_type='text/plain')
//}

プログラミング言語Pythonではブロックはインデントで表します。
ここではreturnで始まる一行がトップページへクライアントがアクセスしてきた時の処理の全てです。

ブラウザでアクセスしてみます。

//image[django-02][Hello Worldサーバ]{
//}

サーバの実装について、詳細な説明は置いておくとして、
ここで重要なことは「HTTPに関するやりとりのほとんどをDjangoが代わりにやってくれている」ということです。
この例では、本章で説明したHTTPレスポンスのContent-Typeとメッセージボディを、
Djangoが提供するHTTPのユーティリティに単に指定しています。
そして、その結果できた、その名もズバリHttpResponseオブジェクトを返しているだけです。

さて、すでにtelnetコマンドを紹介していますから、ここでtelnetで生のHTTPも見てみることにしましょう。

//emlist[telnetでアクセスする]{
(サーバを立ち上げている状態で)
$ telnet 127.0.0.1 8000
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
GET / HTTP/1.1
Host: localhost

HTTP/1.0 200 OK
Date: Tue, 08 Jul 2014 07:53:30 GMT
Server: WSGIServer/0.1 Python/2.7.3
X-Frame-Options: SAMEORIGIN
Content-Type: text/plain

Hello World
Connection closed by foreign host.
//}

それはともかく、返答はできているようです。
@<fn>{http10_is_used}

//footnote[http10_is_used][HTTP/1.1のリクエストに対してHTTP/1.0のレスポンスが返されている点は興味深いですね]

==== Apache上で実行する

これまでのWebサーバはDjango組み込みでしたが、ここでApacheからこのプロジェクトを実行させてみます。

Apache 2.2系列では、例えば次のように記述します。
@<fn>{apache24}

//footnote[apache24][Ubuntu 14.04 LTS等、Apache 2.4が導入されている場合には@<href>{http://httpd.apache.org/docs/2.4/upgrading.html}も確認してください。Apacheの説明だけで1冊本を書けます。]

//emlist[Apacheの設定例]{
WSGIDaemonProcess helloworld user=www-data group=www-data \
   processes=5 threads=5 maximum-requests=5 umask=0007 \
   python-path=/opt/helloworld
WSGIProcessGroup helloworld
WSGIScriptAlias /helloworld /opt/helloworld/helloworld/wsgi.py
<Directory /opt/helloworld/helloworld>
    <Files wsgi.py>
        Order deny,allow
        Allow from all
    </Files>
</Directory>
//}

Apache上にしかるべきモジュールが準備されていれば、上記のhelloworldプロジェクトがApache配下で実行されるようになります。

Webブラウザ上では結果はそっくり同じに見えるはずです。
ここではApacheに対してtelnetをしてみましょう。
なお今回Apache上に施した設定により、Apache上からアクセスする際に"/helloworld"がパスの先頭に必要になります。

//emlist[Apacheにtelnet接続してDjangoプロジェクトのパスへアクセスする]{
$ telnet 127.0.0.1 80
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
GET /helloworld HTTP/1.1
Host: localhost
Connection: close

HTTP/1.1 200 OK
Date: Tue, 08 Jul 2014 08:09:28 GMT
Server: Apache/2.2.22 (Debian)
X-Frame-Options: SAMEORIGIN
Vary: Accept-Encoding
Connection: close
Transfer-Encoding: chunked
Content-Type: text/plain

c
Hello World

0
//}

Djangoが提供するテストサーバと比べると応答がいくつかの点で異なっているのが分かります。
何より、こちらではレスポンスがHTTP/1.1ですね！

なお、WSGIというのは、ApacheのようなWebサーバとPythonプログラムで書かれたWebアプリケーションがやり取りするための規格です。@<fn>{wsgi_spec}
プロジェクト作成時にすでに作られていたwsgi.pyがこの通信部分の面倒を見てくれますので、
開発者はここでも面倒くさいことを行わずに済みます。

//footnote[wsgi_spec][これまた仕様がありますが、RFCではありません]

//image[server-5][ApacheとDjangoのプロジェクトはWSGIを通じてやり取りする]{
//}

ApacheのようなWebサーバはそれ自体、OS内の静的ファイルをルールに従って返答することが出来ますし、その他のプログラミング言語との通信も行えます。
最近では高速化の観点から、Linux等でNginx@<fn>{about_nginx}という別のWebサーバを採用する事例も増えています。
この場合でも、WSGIという規格を介して同じDjangoプロジェクトを利用してWebアプリケーションをクライアントに提供できます。

//footnote[about_nginx][「えんじんえっくす」と読みます。@<href>{http://nginx.org/}]


これ以降の説明では引き続き、Django自身が用意するテスト用のWebサーバを使っていくことにします。
そのためIPアドレスは127.0.0.1、ポート番号は8000のままです。
@<fn>{django_own_server}

//footnote[django_own_server][本文ではDjango自身が提供するWebサーバも使っていますが、これはあくまで開発用のサーバ実装で、Webへの一般公開には全く向きません。まさかHTTP/1.0を返してるとは思いませんでしたが。]


==== HTMLテンプレート

HTTPレスポンスで"text/plain"を指定しましたが、HTMLを返すこともできます。
むしろデフォルトでは（何も指定しない場合）"text/html"をContent-Typeとして返します。

//emlist[HTMLを返す場合のhome()関数]{
def home(request):
    return HttpResponse('<html><body>Hello World</body></html>')
//}

このような形でHTMLを書くのは大変面倒です。@<fn>{wrong_html}

//footnote[wrong_html][そもそもここに書かれているHTMLは適切なHTMLではない気がしますね！]

Webサーバが返答するレスポンスにある程度パターンが決まっているのであれば、
Webサーバでそれを共通化・テンプレート化するほうが色々と楽です。

Djangoを含むWebアプリケーションフレームワークにはしばしばそういった仕組みがあります。
ちょっと試してみましょう。

//emlist[helloworld/settings.pyに"TEMPLATE_DIRS"の行を足す]{
import os
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
TEMPLATE_DIRS = [os.path.join(os.path.dirname(__file__), 'templates')] # <-- ここが追加部分
//}

//emlist[テンプレートの元になるhelloworld/templates/helloworld/hello.djtmlを作る]{
<!DOCTYPE html>
<html>
  <head>
    <title>Hello World Portal</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  </head>
  <body>
    <h1>{{ message }}</h1>
  </body>
</html>
//}

//emlist[helloworld/views.pyのhome()を修正する]{
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect
from django.template import RequestContext, loader

def home(request):
    template = loader.get_template('helloworld/hello.djhtml')
    context = RequestContext(request, {'message': 'Hello World Again!'})
    return HttpResponse(template.render(context))
//}

結果は@<img>{server-6}通りです。

//image[server-6][あげーん]{
//}

ここで重要なのは、テンプレートとなる"hello.djhtml"に{{ message }}という文字列があり、
対応するhome()関数でその部分を"Hello World Again!"に変えるよう指示していることです。

//emlist[hello.djhtmlでテンプレート化されている部分を再掲]{
    <h1>{{ message }}</h1>
//}

//emlist[views.pyでテンプレート部分に実際に文字列を埋め込む部分を再掲@<fn>{about_dict}]{
    context = RequestContext(request, {'message': 'Hello World Again!'})
//}

//footnote[about_dict][{'message': 'Hello World Again!'}の部分ですが、JavaでいうMapに相当する仕組みです（「辞書型データ構造」などと呼ばれます）。keyは"message"、valueが"Hello World Again!"です。]

そのため、次のようにhome()関数を書き換えると、テンプレート側を変更しなくても最終的なHTMLもそれに応じて変化します

//emlist[views.pyでテンプレート部分に実際に文字列を埋め込む部分を再掲@<fn>{about_dict}]{
    context = RequestContext(request, {'message': 'Good Evening Android!'})
//}

==== POSTとデータの保存

いっそ表示させる文字列をユーザに決めてもらいましょう。
具体的にはHTTPのPOSTで送られてきた文字列をサーバに保存し、トップページでは最新のPOSTの結果を表示するようにしてみます。

保存するためには保存するデータ形式を指定する必要があります。
Djangoの場合、Modelという仕組みを用いて指定し、SQLiteのような特定のDBの制約になるべく依らないデータ構造をプログラム中で使うことができます。
@<fn>{need_to_include_to_app}

//footnote[need_to_include_to_app][今回全く本質的でないので省略しますが、helloworldというプロジェクトをDBを持つAppとして登録しておく必要があります。万が一この説明と同じ作業をされている場合には、helloworld/settings.pyのINSTALLED_APPSという変数の最後に'helloworld'を追加してください。]

//emlist[helloworld/models.pyを新規に作成する]{
from django.db import models

class HelloWorldMessage(models.Model):
    message = models.CharField(max_length=100)
    created_at = models.DateTimeField(auto_now_add=True)
//}

ここでクラスを定義し、クラスにはJavaでいう二つのメンバ変数を作ります。

 * message ... 最大100文字のデータ。今回は"Hello World"の代わりとして使うつもり。
 * created_at ... オブジェクトが作られた日時。今回は「最新の結果」を得るためのソートの鍵で使うつもり。

Pythonではプログラムをコンパイルする必要はありません。
しかしこのようにDjangoのModelを定義した際には、使用しているDBに対応する実際のSQLのテーブルなどをDjangoに作ってもらう必要があります。

//emlist[DBを準備するようDjangoにお願いする]{
$ python manage.py syncdb
Creating tables ...
Creating table helloworld_helloworldmessage
Installing custom SQL ...
Installing indexes ...
Installed 0 object(s) from 0 fixture(s)
//}

先ほど、一度dbshellというサブコマンドでSQLite中のテーブルを見ましたね。
ここでもう一度、DBの中身を見てみることにします。

//emlist[SQLiteの中を再度覗くと、元気に駆けまわるhelloworldという文字列が！]{
$ python manage.py dbshell
SQLite version 3.7.11 2012-03-20 11:35:50
Enter ".help" for instructions
Enter SQL statements terminated with a ";"

sqlite> .tables 
auth_group                    auth_user_user_permissions  
auth_group_permissions        django_admin_log            
auth_permission               django_content_type         
auth_user                     django_session              
auth_user_groups              helloworld_helloworldmessage

sqlite> .schema helloworld_helloworldmessage
CREATE TABLE "helloworld_helloworldmessage" (
    "id" integer NOT NULL PRIMARY KEY,
    "message" varchar(100) NOT NULL,
    "created_at" datetime NOT NULL
);
//}

"helloworld_helloworldmessage"というテーブルが新たに作られ、プログラム上で書いた"message"と"created_at"がSQLite上のテーブルのスキーマにあらわれているのが分かります。
Pythonプログラム内でのデータの取り扱いと、SQLエンジンでのデータの取り扱いは、一定のルールに従ってDjangoが代わりに行ないます。

なお、SQLiteではなく、仮にMySQLのような異なるSQLエンジンを使っていた場合にも、同様に適切なテーブルが作られます。
Python側のModelに関する定義をその都度変える必要は通常ありません。
@<fn>{need_to_modify_model}

//footnote[need_to_modify_model][SQLが似ているとは言うものの、個別のSQL実装毎に許す文字列長などは異なります。そういった制約の違いがDjangoの実装に「漏れて」くることがあります。SQLiteで動作するからと言って、MySQLに変更してそのDjangoプロジェクトをそのまま運用へ投入するのは実際的ではありません。]

参考まで、この仕組みをより一般に、プログラム上で見えるオブジェクト（Object）とSQLのような関係データベース（Relational Database）間を
マップする仕組み（Mapper）ということでORM（ORM、Object-relational mapper）と呼んだりします。

さてデータを保存する場所は出来ました。
後はHTTPのPOSTリクエストを受け取る準備をします。
RESTfulには拘らずに/submitというpathにPOSTリクエストがあったら、ということにしましょう。

//emlist[helloworld/urls.pyに"submit"を追加]{
urlpatterns = patterns('',
    url(r'^$', 'helloworld.views.home', name='home'),
    url(r'^submit$', 'helloworld.views.submit', name='submit'),
    url(r'^admin/', include(admin.site.urls)),
)
//}

//emlist[helloworld/views.pyにsubmit()を追加して、home()で結果を使うように変更！]{
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect
from django.template import RequestContext, loader

def home(request):
    result = HelloWorldMessage.objects.order_by('-created_at')
    if len(result) > 0:
        message = result[0].message
    else:
        message = 'Hello World'
    return HttpResponse(u'{}\n'.format(), content_type='text/plain')

def submit(request):
    message = request.POST.get('message')
    obj = HelloWorldMessage.objects.create()
    obj.message = submit
    obj.save()
    return HttpResponseRedirect(reverse('home'))
//}

//emlist[トップページにformを追加する]{
<!DOCTYPE html>
<html>
  <head>
    <title>Hello World Portal</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  </head>
  <body>
    <h1>{{ message }}</h1>
    <form action="{% url 'submit' %}" method="post">
      <input type="text" name="message">
      <input type="submit" value="Submit">
    </form>
  </body>
</html>
//}

//image[server-7][フォームが表示されました]{
//}

そこで、例えば"Hello Android!"と入れて、Submitボタンをクリックします。
これで文字が変わると思いきや。

//image[server-8][謎のエラー]{
//}

おや？

==== CSRF脆弱性と、それを軽減するDjangoの仕組み

#@warn(TODO: CSRF脆弱性の説明がモヒカン耐性を持つ程度に正確か怪しい。要確認)

@<img>{server-8}には英語の説明がズラズラ表示されています。@<fn>{not_shown_on_production}
文中にはDjango特有の説明も多数書かれているのでここで逐一説明することは避けますが、要は「Cross Site Request Forgery」の疑いがある、と警告しています。

//footnote[not_shown_on_production][本番環境では表示されません。具体的にはhelloworld/settings.pyにDEBUGという変数があり、プロジェクトが作成されたときにはこれがTrue（Javaで言う boolean の true）に設定されているため、うやうやしく理由を説明してくれています。本番環境で同じミスがあった場合、HTTPの403（Forbidden）を返します。ここでは説明しませんが、404や403といったステータスコードに対応したHTMLをDjangoに指定することもできます。]

先ほど準備したテンプレートのform部分は大変シンプルです。
単純に「message」というインプットと、ボタンを兼ねる「submit」というインプットの二つしかありません。
ユーザは実際、テキスト入力フィールド一つとボタンだけ見ることになります。
formタグに指定がある通り、この2つのフィールドがPOSTメソッドとともにHTTPリクエストで送信されます。

さて、HTTPの基本的なやり取りを思い出しながら、以下の質問について考えてみてください。
「このPOSTリクエスト、そのフォームをユーザが見なくても送信できませんか？」

実際にWebページを見ないで送る例を示します。
curlコマンドの再登場です

//emlist[curlのPOST実行例]{
$ curl -v -F 'message=Malicious Message' http://localhost:8000/submit
//}

仮にDjangoが止めてくれなかったとしますと、このコマンドでメッセージを書き込みたい放題です。
@<img>{server-9}のような画面を後の人々は見ることになるでしょう。
@<fn>{csrf_exempt}

//footnote[csrf_exempt][ここで紹介するDjangoのセキュリティ機構を無理やり止めて画面を表示させています。具体的には、submit()関数に"@csrf_exempt"という「デコレータ」をつけると、Djangoは今回説明している機構を止めてしまい、ここでの悪意のある例が動作します。]

//image[server-9][Malicious Messageが書き込まれてしまった]{
//}

//emlist[curlのPOST実行例]{
$ curl -v -F 'message=こんにちはこんにちは！ぼくもわもわさん！' http://localhost:8000/submit
//}

//image[server-10][わー、また書き込まれてしまった]{
//}

POSTリクエストがその人自身が画面を見て送信してきたものなのか、
悪意のあるWebページからのものなのか、
Webサーバが区別する方法がHTTPには組み込まれていません。
そのため、この「素の」フォームでは、悪意のある相手は結構好き勝手出来てしまいます。

上の例ではcurlで独立にデータを送信していますが、もっと厄介な方法があります。
悪意のあるWebサイトに同一のPOSTリクエストを送る機能をこっそり埋め込んでおくのです。
そうすると、そのWebサイトを訪れた善良な第三者は、気づかないうちにこの「攻撃」を行ってしまいます。

今回の事例では単にトップページが書き換わるだけです。
しかし、仮にログインをして利用するサービスにこの問題があると、困ります。

 * オンラインショッピングサイトなら、ものを買い放題
 * 銀行であれば、送金し放題
 * パスワードを変更し放題

こういった背景から発生する脆弱性を、一般にCSRF（Cross Site Request Forgery）脆弱性と呼びます。
日本語で言えば「サイト間をまたぐリクエスト強制」で、
ユーザが知らない間に何らかのHTTPリクエストを強制されてる脆弱性、ということです。
@<fn>{curl_example_may_not_be_csrf}

//footnote[curl_example_may_not_be_csrf][正確にはcurlによる不正なアップデートよりも、ログイン後の各種の大事な情報アップデートを相手にされてしまう状態がCSRF脆弱性です。curlで起こした書き換えの方は、どちらかというとDOS攻撃の元になります。]

さて@<img>{server-9}と@<img>{server-10}は、これまで実装してきた実際のDjangoのアプリケーションの画面ではありませんでした。
実際に表示されたのは@<img>{server-8}です。

実は、DjangoはCSRF脆弱性に関する上記の問題を認識しており、
今回の例ではエラーを表示して、これ以上このPOSTリクエストを処理することを拒否したのです。

偉い！

さて、DjangoはWebサーバを攻撃っぽいものから守ろうとしていますが、ここで私達の「正当な要求」が拒否されている点は問題です。
「正当だ。このフォームから、正しく送ったんだ！」ということを示すものが必要です。

というわけで説明が長くなりましたが、とりあえず今回はフォームに一行追加します。
@<fn>{not_perfect}

//footnote[not_perfect][CSRFの全てをここで説明しているわけではありません。大事なデータの変更の場合「入力」「確認」「完了」の3段階を踏むこともあります。また、CSRFを防ぐ方法は他にも「直前でもう一度パスワードを求める」「ハードウェアトークンの値を要求する」など、幅があります。IPA（情報処理推進機構）がオンラインで無料公開している「安全なウェブサイトの作り方」など、無料で得られる信頼性の高い情報もありますので、そちらも参照してください。]

//emlist[トップページのフォームを改良する]{
<!DOCTYPE html>
<html>
  <head>
    <title>Hello World Portal</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  </head>
  <body>
    <h1>{{ message }}</h1>
    <form action="{% url 'submit' %}" method="post">
      {% csrf_token %}
      <input type="text" name="message">
      <input type="submit" value="Submit">
    </form>
  </body>
</html>
//}

{% csrf_token %}を追加しただけですが、これで基本的なCSRF脆弱性の対処が出来ました。
@<fn>{csrf_token_is_mentioned}

//footnote[csrf_token_is_mentioned][エラー画面をよく見ると実際、ここで追加している内容を提案しています。]

実際にWebサーバに送られるHTMLを見てみましょう

//emlist[実際に送られてきた内容の一例]{
<!DOCTYPE html>
<html>
  <head>
    <title>Hello World Portal</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  </head>
  <body>
    <h1>Hello World</h1>
    <form action="/submit" method="post">
      <input type='hidden' name='csrfmiddlewaretoken' value='MlTmHwtCNrLgCjsbpRzoCL9bNbVjIQW' />
      <input type="text" name="message">
      <input type="submit" value="Submit">
    </form>
  </body>
</html>
//}

csrfmiddlewaretokenの値が、簡単には予測不可能な値である点に注目します。

//emlist[おわかりいただけただろうか？]{
<input type='hidden' name='csrfmiddlewaretoken' value='MlTmHwtCNrLgCjsb :-) pRzoCL9bNbVjIQW' />
//}

あ、間違えた。

//emlist[CSRF脆弱性を防ぐための秘密の値が埋め込まれている]{
<input type='hidden' name='csrfmiddlewaretoken' value='MlTmHwtCNrLgCjsbpRzoCL9bNbVjIQW' />
//}

この値は、Django自身が、擬似乱数を用いて独自に生成したものです。
自身のDBの中に保存しておき、以降のPOSTリクエストでこの値が埋め込まれているかをチェックします。

CSRF脆弱性はこのフィールドでどのように克服されるのでしょうか。

まず、curlコマンドは上記のトップページ（フォームが表示されるページ）をその都度見るまで動作しなくなります。
csrfmiddlewaretokenというフォーム内の値を予測できないためです。

同様に、攻撃者のWebページからも、直接有害なPOSTリクエストを送れなくなりました。
正確には、そのPOSTリクエストはDjangoによって拒否されます。

今回の例ではまだログインを実装していないため特に意味はなさそうです。
どうにしても、彼らは手動でこのフォームに書き込みにくるでしょう。

しかし後述するログインを実装すると話は変わります。
このcsrf_tokenなるもののあるなしで、悪意のあるWebサイトがこのユーザになりすまして
ユーザの大事な情報を書き換えてしまったり出来るかどうかが変わってきます。
CSRF脆弱性のあるなしがテンプレート中の一行のあるなしで決まるのです。
@<fn>{in_cookie}

//footnote[in_cookie][ユーザ専用の秘密が使いまわされてしまいそうですね。実はDjangoは HTTP Cookie にも情報を残していて、POSTリクエストがあった際には密かに両方の値をチェックしています。そのため、単なる使い回しはうまく行きません。ただしCookieの中身が漏れるとまずいことがありそうです。ところで、Cookie漏れの脆弱性というのも、世の中には存在します。]

==== おおっと、クロスサイトスクリプティングはどうした！

比較的話題に上がりづらいCSRF脆弱性ばかり説明していましたが、世の中の脆弱性はこれだけではありません。
特に有名なクロスサイトスクリプティング脆弱性、今回はどうでしょうか。

試してみましょう。

//image[server-11][典型的なXSS脆弱性のチェック]

//image[server-12][あれ？]

Djangoのテンプレートシステムは標準でXSS対策のために典型的な文字をエスケープする処理を勝手に行います。
そのため、単純にフォームからデータを流し込むだけであれば、非常によく例に挙げられるたぐいのXSSは自動的に避けられます。

この機能をオフにしてXSSを許してみましょう。

//emlist[テンプレートであるhome.djhtmlに「この文字列はエスケープの必要がない」と指定すると]{
    <h1>{{ message|safe }}</h1>
//}

//image[server-13][XSSが成立した]

実際にこの自動エスケープを切ることはあります。
例えばテンプレートの出来る範囲を超えて動的にHTMLを生成したい場合、
生のPython言語でHTMLの部品となる文字列そのものを作成する必要があります。
そのような場合に上記のようにDjangoの自動エスケープを切るわけですが、
そのときにはDjangoであってもXSS脆弱性のあるWebアプリケーションが生まれる余地が生まれます。
@<fn>{great_service_has_no_way_to_avoid_xss}

//footnote[great_service_has_no_way_to_avoid_xss][高度なことを行うアプリケーションほど、標準的なエスケープをされると困るケースが多くなる傾向があると思います。そういった状況ではしばしばプログラマが自己責任でXSSの可能性を潰す必要が出てきます。]

==== パスワードに基づくログインを実装する

これまではゲストユーザでもトップページを変更できました。
言い換えると、「認証」してないのに書き込むことの「認可」を与えている状態でした。
これは、一般的とは到底言えません。

そこで、Python + Djangoによる実装の最後ではユーザによるログイン、すなわち「認証」を実装してみます。
認証後、認証情報はCookieに保存され、セッションが維持されます。
@<fn>{not_basic}

//footnote[not_basic][ここで行う認証は「フォーム認証」です。BASIC認証やDIGEST認証ではありません。]



これもDjangoの仕組みを使うことで大幅に実装を簡略化することができます。

まずユーザを作る必要があります。
ここではPythonのインタラクティブ環境でユーザを作っています。
本当はWeb上でユーザ登録フォームが必要なところです。

//emlist[ユーザを作る]{
$ python manage.py shell
...
>>> from django.contrib.auth.models import User
>>> User.objects.create_user(username='mowa', email='mowa@example.com', password='mowa2mowa')
//}

次にログイン画面を表示するURI（のpath）とViewの対応関係を指定します。
ここではDjangoが提供するログインモジュールをViewとしてしまいます。

//emlist[urls.pyにDjangoのパスワードログイン用のモジュールを指定する]{
urlpatterns = patterns('',
    url(r'^accounts/login/$', 'django.contrib.auth.views.login',
        {'template_name': 'helloworld/login.djhtml'}),
    url(r'^$', 'helloworld.views.home', name='home'),
    url(r'^submit$', 'helloworld.views.submit', name='submit'),
    url(r'^admin/', include(admin.site.urls)),
)
//}

次に、ログイン用モジュールが参照するログイン画面を作ります。
@<fn>{about_this_template}

//footnote[about_this_template][このテンプレートでテンプレートされている変数はどれも、実際にはDjangoが提供するログイン用モジュールが使います。この機能で十分であれば、Webアプリケーション作者はHTMLの見栄えだけテンプレートを介して変更すればよいわけです。]

//emlist[login.djhtml]{
<!DOCTYPE html>
<html>
  <head>
    <title>Login Page</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  </head>
  <body>
    {% if form.errors %}
      <p>Login Failure</p>
    {% endif %}
    <form method="post" action="{% url 'django.contrib.auth.views.login' %}">
      {% csrf_token %}
      <table>
        <tr>
          <td>{{ form.username.label_tag }}</td>
          <td>{{ form.username }}</td>
        </tr>
        <tr>
          <td>{{ form.password.label_tag }}</td>
          <td>{{ form.password }}</td>
        </tr>
      </table>
      <input type="submit" value="login" />
      <input type="hidden" name="next" value="{{ next }}" />
    </form>
  </body>
</html>
//}

これまで作った2つのViewをログイン必須とします。

//emlist[login_required]{
from django.contrib.auth.decorators import login_required
...

@login_required
def home(request):
    ...

@login_required
def submit(request):
    ...
//}

これでWebサーバの準備終了です。
@login_requiredが付けられたViewでは、ユーザは自動的にログインページにリダイレクトされます。

//image[server-14][XSSが成立した]

さて、curlでHTTPの中身を見つつこのログイン過程をおさらいして、Djangoとお別れしましょう。

curlではCookieを保存するファイル、読み込むファイルを-cと-bで分けて記述します。
しかしそれ以外については、これまでの説明でひと通り何が起きているかを理解できると信じています。

#@warn(TODO: さすがに全部表示するのは冗長かなぁ、と反省中)

//emlist[トップページは302]{
$ curl -v -b /tmp/cookie.txt -c /tmp/cookie.txt http://127.0.0.1:8000/
* About to connect() to 127.0.0.1 port 8000 (#0)
*   Trying 127.0.0.1...
* connected
* Connected to 127.0.0.1 (127.0.0.1) port 8000 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.26.0
> Host: 127.0.0.1:8000
> Accept: */*
> 
* additional stuff not fine transfer.c:1037: 0 0
* HTTP 1.0, assume close after body
< HTTP/1.0 302 FOUND
< Date: Thu, 10 Jul 2014 07:18:17 GMT
< Server: WSGIServer/0.1 Python/2.7.3
< Vary: Cookie
< X-Frame-Options: SAMEORIGIN
< Content-Type: text/html; charset=utf-8
< Location: http://127.0.0.1:8000/accounts/login/?next=/
< 
* Closing connection #0
//}

//emlist[ログイン画面が返される]{
$ curl -v -b /tmp/cookie.txt -c /tmp/cookie.txt http://127.0.0.1:8000/accounts/login/?next=/
* About to connect() to 127.0.0.1 port 8000 (#0)
*   Trying 127.0.0.1...
* connected
* Connected to 127.0.0.1 (127.0.0.1) port 8000 (#0)
> GET /accounts/login/?next=/ HTTP/1.1
> User-Agent: curl/7.26.0
> Host: 127.0.0.1:8000
> Accept: */*
> 
* additional stuff not fine transfer.c:1037: 0 0
* HTTP 1.0, assume close after body
< HTTP/1.0 200 OK
< Date: Thu, 10 Jul 2014 07:18:51 GMT
< Server: WSGIServer/0.1 Python/2.7.3
< Expires: Thu, 10 Jul 2014 07:18:51 GMT
< Vary: Cookie
< Last-Modified: Thu, 10 Jul 2014 07:18:51 GMT
< Cache-Control: max-age=0
< X-Frame-Options: SAMEORIGIN
< Content-Type: text/html; charset=utf-8
* Added cookie csrftoken="PAxGoYK7u4DxuSIbTS1ltg29OEF82Ac8" for domain 127.0.0.1, path /, expire 1436426331
< Set-Cookie:  csrftoken=PAxGoYK7u4DxuSIbTS1ltg29OEF82Ac8; expires=Thu, 09-Jul-2015 07:18:51 GMT; Max-Age=31449600; Path=/
< 
<!DOCTYPE html>
<html>
  <head>
    <title>Login Page</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  </head>
  <body>
    

    <form method="post" action="/accounts/login/">
      <input type='hidden' name='csrfmiddlewaretoken' value='PAxGoYK7u4DxuSIbTS1ltg29OEF82Ac8' />
      <table>
        <tr>
          <td><label for="id_username">Username:</label></td>
          <td><input id="id_username" maxlength="254" name="username" type="text" /></td>
        </tr>
        <tr>
          <td><label for="id_password">Password:</label></td>
          <td><input id="id_password" name="password" type="password" /></td>
        </tr>
      </table>
      <input type="submit" value="login" />
      <input type="hidden" name="next" value="/" />
    </form>
  </body>
* nread <= 0, server closed connection, bailing
* Closing connection #0
</html>
//}

//emlist[ユーザ名とパスワードとCSRFトークンを送信する。ユーザ名とパスワードは先に用意した通り]{
$ curl -v -b /tmp/cookie.txt -c /tmp/cookie.txt -F "csrfmiddlewaretoken=PAxGoYK7u4DxuSIbTS1ltg29OEF82Ac8" -F "username=mowa" -F "password=mowa2mowa" http://127.0.0.1:8000/accounts/login/?next=/
* About to connect() to 127.0.0.1 port 8000 (#0)
*   Trying 127.0.0.1...
* connected
* Connected to 127.0.0.1 (127.0.0.1) port 8000 (#0)
> POST /accounts/login/?next=/ HTTP/1.1
> User-Agent: curl/7.26.0
> Host: 127.0.0.1:8000
> Accept: */*
> Cookie: csrftoken=PAxGoYK7u4DxuSIbTS1ltg29OEF82Ac8
> Content-Length: 393
> Expect: 100-continue
> Content-Type: multipart/form-data; boundary=----------------------------309989bff083
> 
* additional stuff not fine transfer.c:1037: 0 0
* additional stuff not fine transfer.c:1037: 0 0
* Done waiting for 100-continue
* additional stuff not fine transfer.c:1037: 0 0
* additional stuff not fine transfer.c:1037: 0 0
* HTTP 1.0, assume close after body
< HTTP/1.0 302 FOUND
< Date: Thu, 10 Jul 2014 07:27:21 GMT
< Server: WSGIServer/0.1 Python/2.7.3
< Expires: Thu, 10 Jul 2014 07:27:21 GMT
< Vary: Cookie
< Last-Modified: Thu, 10 Jul 2014 07:27:21 GMT
< Location: http://127.0.0.1:8000/
< Cache-Control: max-age=0
< X-Frame-Options: SAMEORIGIN
< Content-Type: text/html; charset=utf-8
* Replaced cookie csrftoken="t2t4kigdSwvfT8owzUDYoN3VUT7pKqfG" for domain 127.0.0.1, path /, expire 1436426841
< Set-Cookie:  csrftoken=t2t4kigdSwvfT8owzUDYoN3VUT7pKqfG; expires=Thu, 09-Jul-2015 07:27:21 GMT; Max-Age=31449600; Path=/
* Added cookie sessionid="cofmgjc0tv16k8pi6ho4wik9oxlyk6p4" for domain 127.0.0.1, path /, expire 1406186841
< Set-Cookie:  sessionid=cofmgjc0tv16k8pi6ho4wik9oxlyk6p4; expires=Thu, 24-Jul-2014 07:27:21 GMT; httponly; Max-Age=1209600; Path=/
< 
* Closing connection #0
//}

//emlist[ログインセッションがCookieに残っているため、フォームが表示された]{
curl -v -b /tmp/cookie.txt -c /tmp/cookie.txt http://127.0.0.1:8000/
* About to connect() to 127.0.0.1 port 8000 (#0)
*   Trying 127.0.0.1...
* connected
* Connected to 127.0.0.1 (127.0.0.1) port 8000 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.26.0
> Host: 127.0.0.1:8000
> Accept: */*
> Cookie: sessionid=cofmgjc0tv16k8pi6ho4wik9oxlyk6p4; csrftoken=t2t4kigdSwvfT8owzUDYoN3VUT7pKqfG
> 
* additional stuff not fine transfer.c:1037: 0 0
* HTTP 1.0, assume close after body
< HTTP/1.0 200 OK
< Date: Thu, 10 Jul 2014 07:27:41 GMT
< Server: WSGIServer/0.1 Python/2.7.3
< Vary: Cookie
< X-Frame-Options: SAMEORIGIN
< Content-Type: text/html; charset=utf-8
* Replaced cookie csrftoken="t2t4kigdSwvfT8owzUDYoN3VUT7pKqfG" for domain 127.0.0.1, path /, expire 1436426861
< Set-Cookie:  csrftoken=t2t4kigdSwvfT8owzUDYoN3VUT7pKqfG; expires=Thu, 09-Jul-2015 07:27:41 GMT; Max-Age=31449600; Path=/
< 
<!DOCTYPE html>
<html>
  <head>
    <title>Hello World Portal</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  </head>
  <body>
    <h1>&lt;script&gt;alert(&quot;やぁ&quot;)&lt;/script&gt;</h1>
    <form action="/submit" method="post">
      <input type='hidden' name='csrfmiddlewaretoken' value='t2t4kigdSwvfT8owzUDYoN3VUT7pKqfG' />
      <input type="text" name="message">
      <input type="submit" value="Submit">
    </form>
  </body>
</html>
* nread <= 0, server closed connection, bailing
* Closing connection #0
//}

//emlist[古代文明に打ち勝ちました@<fn>{about_this_curl}]{
$ curl -L -b /tmp/cookie.txt -c /tmp/cookie.txt -F "csrfmiddlewaretoken=t2t4kigdSwvfT8owzUDYoN3VUT7pKqfG" -F "message=HTTPの勲章" http://127.0.0.1:8000/submit 
<!DOCTYPE html>
<html>
  <head>
    <title>Hello World Portal</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  </head>
  <body>
    <h1>HTTPの勲章</h1>
    <form action="/submit" method="post">
      <input type='hidden' name='csrfmiddlewaretoken' value='t2t4kigdSwvfT8owzUDYoN3VUT7pKqfG' />
      <input type="text" name="message">
      <input type="submit" value="Submit">
    </form>
  </body>
</html>
//}

//footnote[about_this_curl][ここだけ、ちょっと冗長すぎるため-vオプションをなくして-Lオプションをつけました。HTTPステータスコード300番代をcurlが認識してリダイレクト先を取得してくれるオプションです。telnetだとこういったことは出来ません]

====[column] RESTfulは？

今回は、REST風のインターフェースでした。
RESTfulの説明もしたのだから、概要くらいは書いたほうが良さそうですね。

まず、Djangoが提供するHttpRequest、HttpResponseオブジェクトは
HTTPのやりとりの多くを柔軟に行う方法を多数提供しています。
HttpRequestオブジェクトではmethodというメンバ変数が"GET"や"POST"といったHTTPのメソッドを文字列で保持しており、
HttpResponseオブジェクトはステータスコードを保持するstatus_codeというメンバ変数を持ちます。
後はpathをRESTfulに見合った方法で記述すれば、RESTfulなWebアプリを作ることができます。
@<fn>{django_is_good_for_rest}

//footnote[django_is_good_for_rest][『RESTful Webサービス』では12章「RESTfulサービスのためのフレームワーク」でDjangoによる同書の実践方法が記述されています。「Djangoは主にWebアプリケーションに使用されるが、RESTful WebサービスをPythonで実装するのに申し分ない土台になる」(同書 p385)]

異なるアプローチもあります。
例えば、Django本体に追加して、Django REST framework（@<href>{http://www.django-rest-framework.org/}）を用いる方法があります。
ここでは説明を省略しますが、これを用いてRESTfulなサービスを構築することも出来ます。

====[/column]

== さらなる学習のために

本章ではWebサーバと通信する上で必要な基礎知識について説明し、最後にWebサーバ上のアプリケーションを実際に実装する例も説明しました。

しかし、WebとWebサーバを理解する上では、多くの面でまだ不足があります。
本章の最後に参考書籍をいくつか挙げていきますので、適宜参照してみてください。

 * 『HTTPの教科書』翔泳社
 ** 通信プロトコルとしてのHTTPをとりあえず読むのに手軽だとおもわれます。
 * 『Webを支える技術』技術評論社
 ** 本章で押さえていないWebの細かいパラダイムについては後者が詳細です。
 * 『めんどうくさいWebセキュリティ』翔泳社
 ** Webの細かく複雑な点がたくさん説明されています。あまり初心者向けとは言いがたいです
 * 『コンピュータネットワーク 第5版』
 ** ネットワークの教科書です。HTTPというよりも全体の再設計を考えたいときに。
 * 『RESTful Webサービス』
 ** RESTfulの数少ない本です
 * 『過負荷に耐えるWebの作り方』
 ** 第一回AKB総選挙の設計から実装について書かれています。短納期というのもおもしろい。
 * 『安全なWebアプリケーションの作り方』SoftBank Creative
 ** 言語はPHPですが基本的な脆弱性と対策について学べます

なお、本章ですでに説明したとおり、2014年に入ってHTTP/1.1の仕様改定がありました。
HTTP/1.1という表現で差すものが、各書籍の時点と変わっていることがあります。

Webに関する書籍は上記の一部も含めて、しばしば「既存のHTTP/1.1の問題」という形でRFC 2616に関わる落とし穴や問題点を指摘することがあります。
しかし、新仕様によってそれらの一部は「バグ修正」されていたりして、仕様に関する問題が消滅していることがあるため、教養としても理解する意味が薄くなっている可能性があります。
@<fn>{implementation_wont_yet}
@<fn>{http_20_will_solve}
特にHTTPというプロトコルに特化して何かを調べたい、という場合には特に注意してください。

//footnote[implementation_wont_yet][実装に関わる問題は新RFCとは独立して発生しているため、事情が異なります。サポートの切れたWebサーバ実装の特定のバージョンを使い続けていたり、サポートの切れたOSのWebブラウザを使っていたりする場合、仕様が良くなっていても、それに合わせて実装を修正する人がいません。]
//footnote[http_20_will_solve][ある書籍では「きたるHTTP 2.0が解決してくれるに違いない」という文面も見ました。HTTP/1.1自身が実は変わる、という可能性には気が付かなかった模様です。実際、バージョン番号まで決まって10年以上安定している仕様自体がまるっと修正されるとは思いませんよね]

==[column] RFCへの「コメント」は誰でもできる

HTTPとはあまり関係しない別のRFCのワーキングループに、筆者も一時期参加していたことがあります。
実装する上で使用上に若干課題があり、旧仕様の問題箇所の修正を新しいRFCに入れて欲しかったのです。

非常にシンプルで説得力があったせいか、結果として特に異議もなく採用され、
同RFCのAcknowledgementの項に名前が掲載されました。
普段こういうことはあまりないだけに、結構うれしいものです。

ここで大事なことは、IETFでの議論は一般に広く開かれているということです。
一介の技術者が、世界的に使われる仕様に意見を出すことはいつでも可能です。

議論は通常英語で行われます。

==[/column]
